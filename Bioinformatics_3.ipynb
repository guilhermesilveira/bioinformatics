{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bioinformatics 3",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRc2uXzh8AoS"
      },
      "source": [
        "import math\r\n",
        "import numpy as np\r\n",
        "from typing import List"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWtePF9-GOms"
      },
      "source": [
        "import sys\r\n",
        "\r\n",
        "sys.setrecursionlimit(10**6) \r\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h69ZtdPk8E_R"
      },
      "source": [
        "import requests\r\n",
        "\r\n",
        "# reads an uri and returns its content split by line, deals with \\n and \\r\r\n",
        "def read_uri(uri):\r\n",
        "  response = requests.get(uri)\r\n",
        "  content = response.text.strip().replace(\"\\r\", \"\").split(\"\\n\")\r\n",
        "  return content"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AX5Z9YDXKYR6"
      },
      "source": [
        "def dp_change(money, coins):\r\n",
        "  # [0  1  2  3  4  5  6  7  8  9 10]\r\n",
        "  # [1 0 0 0 0 0 0 0 0 0 0]\r\n",
        "  # [0 1 0 1 0 0 0 0 0 0 0]\r\n",
        "  # [0 0 2 0 2 0 2 0 0 0 0]\r\n",
        "  # [0 0 0 3] i don't care about this situation\r\n",
        "  # [0 0 0 0 4]\r\n",
        "  possibles = [math.inf] * (money+1)\r\n",
        "  possibles[0] = 1\r\n",
        "  # assuming its always possible as if there is always a 1 coin denomination\r\n",
        "  for j in range(len(possibles)):\r\n",
        "    if possibles[j]:\r\n",
        "      for coin in coins:\r\n",
        "        if j + coin <= money:\r\n",
        "          possibles[j + coin] = min(possibles[j] + 1, possibles[j + coin])\r\n",
        "  return possibles[money] - 1"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GmYkufVXV3ty",
        "outputId": "950b1bf4-0955-4dba-871d-543367929ae6"
      },
      "source": [
        "print(dp_change(40,[50,25,20,10,5,1]))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2mHwRCjV5my",
        "outputId": "7a8d7244-88fb-4578-d6aa-dfa3454ddd6b"
      },
      "source": [
        "dp_change(17028, [14,5,3,1]) # 1218"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1218"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09ypeRMkXetZ"
      },
      "source": [
        "def list_string_to_ints(s):\r\n",
        "  return list(map(int, s.split()))\r\n",
        "\r\n",
        "def read_manhattan(uri):\r\n",
        "  content = read_uri(uri)\r\n",
        "  n, m = list(map(int, content[0].split()))\r\n",
        "  down = np.array(list(map(list_string_to_ints, content[1:n+1])))\r\n",
        "  right = np.array(list(map(list_string_to_ints, content[n+2:2*n+3])))\r\n",
        "  print(down, right)\r\n",
        "  return n, m, down, right"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XxxxP5za8QZu",
        "outputId": "9c89cf15-25e7-4df9-8cce-4af88a38ee7b"
      },
      "source": [
        "read_manhattan(\"https://raw.githubusercontent.com/guilhermesilveira/bioinformatics/main/datasets/manhattan.txt\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1 0 2 4 3]\n",
            " [4 6 5 2 1]\n",
            " [4 4 5 2 1]\n",
            " [5 6 8 5 3]] [[3 2 4 0]\n",
            " [3 2 4 2]\n",
            " [0 7 3 3]\n",
            " [3 3 0 2]\n",
            " [1 3 2 2]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 4, array([[1, 0, 2, 4, 3],\n",
              "        [4, 6, 5, 2, 1],\n",
              "        [4, 4, 5, 2, 1],\n",
              "        [5, 6, 8, 5, 3]]), array([[3, 2, 4, 0],\n",
              "        [3, 2, 4, 2],\n",
              "        [0, 7, 3, 3],\n",
              "        [3, 3, 0, 2],\n",
              "        [1, 3, 2, 2]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5HBCNUg9RNN"
      },
      "source": [
        "def longest_path(n, m, down, right):\r\n",
        "\r\n",
        "  # print(n, m, len(down), len(right))\r\n",
        "\r\n",
        "  maximal = [0] * (m+1)\r\n",
        "  for j in range(1, m + 1):\r\n",
        "    maximal[j] = maximal[j - 1] + right[0][j - 1]\r\n",
        "\r\n",
        "  # print(maximal)\r\n",
        "\r\n",
        "  for i in range(1, n+1):\r\n",
        "    new_maximal = [0] * (m + 1)\r\n",
        "    new_maximal[0] = maximal[0] + down[i - 1][0]\r\n",
        "    for j in range(1, m+1):\r\n",
        "      up = maximal[j] + down[i - 1][j]\r\n",
        "      left = new_maximal[j-1] + right[i][j - 1]\r\n",
        "      new_maximal[j] = max(up, left)\r\n",
        "    maximal = new_maximal\r\n",
        "  return maximal[m]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UtiVzvx3-hTr",
        "outputId": "f3003dbd-fce7-4f4f-f9ae-215c3a59cc70"
      },
      "source": [
        "longest_path(*read_manhattan(\"https://raw.githubusercontent.com/guilhermesilveira/bioinformatics/main/datasets/manhattan.txt\"))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1 0 2 4 3]\n",
            " [4 6 5 2 1]\n",
            " [4 4 5 2 1]\n",
            " [5 6 8 5 3]] [[3 2 4 0]\n",
            " [3 2 4 2]\n",
            " [0 7 3 3]\n",
            " [3 3 0 2]\n",
            " [1 3 2 2]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "34"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSxxM-dc-kPt",
        "outputId": "53670866-91c3-48b4-da7c-2e0941ac280b"
      },
      "source": [
        "longest_path(*read_manhattan(\"https://raw.githubusercontent.com/guilhermesilveira/bioinformatics/main/datasets/dataset_261_10.txt\"))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[4 3 3 1 3]\n",
            " [0 2 3 0 4]\n",
            " [3 1 2 2 4]\n",
            " [4 4 2 0 0]\n",
            " [1 2 1 4 0]\n",
            " [1 1 0 4 1]\n",
            " [1 0 1 2 0]\n",
            " [4 1 1 3 0]\n",
            " [4 2 0 1 3]\n",
            " [1 0 2 0 1]] [[3 4 0 0]\n",
            " [3 1 4 3]\n",
            " [4 1 1 1]\n",
            " [0 3 3 2]\n",
            " [4 4 1 0]\n",
            " [0 0 1 4]\n",
            " [3 0 2 3]\n",
            " [0 2 4 1]\n",
            " [3 1 4 3]\n",
            " [3 3 4 3]\n",
            " [2 1 4 2]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "40"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4C7rYA9Bjg6"
      },
      "source": [
        "def lcs(v, w):\r\n",
        "  lv = len(v)\r\n",
        "  lw = len(w)\r\n",
        "  s = np.zeros((lv + 1, lw + 1))\r\n",
        "  backtrack = np.zeros(s.shape)\r\n",
        "  for i in range(1, lv + 1):\r\n",
        "    for j in range(1, lw + 1):\r\n",
        "      matches = v[i-1] == w[j-1]\r\n",
        "      s[i, j] = max(s[i-1,j], s[i,j-1], s[i-1,j-1] + matches)\r\n",
        "      if s[i,j] == s[i-1,j]:\r\n",
        "          backtrack[i, j] = 1\r\n",
        "      elif s[i, j] == s[i, j-1]:\r\n",
        "          backtrack[i, j] = 2\r\n",
        "      else:\r\n",
        "          backtrack[i, j] = 0\r\n",
        "      # print(i, j, matches, v[i-1], w[j-1])\r\n",
        "      # print(s, backtrack)\r\n",
        "  return s, backtrack\r\n",
        "\r\n",
        "def lcs_output(backtrack, v, i, j):\r\n",
        "  # print(i, j)\r\n",
        "  if i == 0 or j == 0:\r\n",
        "    return \"\"\r\n",
        "  if backtrack[i, j] == 1:\r\n",
        "      return lcs_output(backtrack, v, i - 1, j)\r\n",
        "  elif backtrack[i, j] == 2:\r\n",
        "      return lcs_output(backtrack, v, i, j - 1)\r\n",
        "  else:\r\n",
        "      return lcs_output(backtrack, v, i - 1, j - 1) + v[i-1]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 189
        },
        "id": "lVD9_ljkCrsU",
        "outputId": "a7a58b01-f69a-4b19-daca-04afe53e463c"
      },
      "source": [
        "s, bt = lcs(\"AACCTTGG\", \"ACACTGTGA\")\r\n",
        "print(bt)\r\n",
        "lcs_output(bt, \"AACCTTGG\", len(\"AACCTTGG\"), len(\"ACACTGTGA\"))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 2. 2. 2. 2. 2. 2. 2. 2.]\n",
            " [0. 1. 1. 0. 2. 2. 2. 2. 2. 2.]\n",
            " [0. 1. 0. 1. 0. 2. 2. 2. 2. 2.]\n",
            " [0. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            " [0. 1. 1. 1. 1. 0. 2. 2. 2. 2.]\n",
            " [0. 1. 1. 1. 1. 1. 1. 0. 2. 2.]\n",
            " [0. 1. 1. 1. 1. 1. 0. 1. 0. 2.]\n",
            " [0. 1. 1. 1. 1. 1. 1. 1. 1. 1.]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'AACTTG'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "id": "-8PFsCDgCyD4",
        "outputId": "196ed1fb-5de3-4c1f-ac7d-e252aabbbd84"
      },
      "source": [
        "s, bt = lcs(\"AA\", \"AC\")\r\n",
        "print(s)\r\n",
        "print(bt)\r\n",
        "lcs_output(bt, \"AA\", len(\"AA\"), len(\"AC\"))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 0.]\n",
            " [0. 1. 1.]\n",
            " [0. 1. 1.]]\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 2.]\n",
            " [0. 1. 1.]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'A'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "id": "PDLUe0KcFVBO",
        "outputId": "d5041b7a-eafe-4a84-cb95-a9ca901c019a"
      },
      "source": [
        "s1,s2 = \"CTTTTACGAGATACTCAGCCACTTCAATCCTGAGGATCGACAGGGTTATTGGCAGACAGGGCAATGCCGTTTTGCCCTGGATCGTACTGGCTTCCCCATTTATACCTCAGACATTTCATGAGTTGTCGACTCTCTCATACTATGTGCAAATTTATCCCCACGATGGGAACGATTACATATACTGGGCAGTGGATTGCGGTAAAATCGGCTGATCTGCAATGATGATTTGAAATTTCGTCTGCCCGGGATCGGTCTCGAAGAGAATTCATAATGCTTAAGCCTATACTTACAGCTATAGTGAGTCAATGAGTTACCTTAGGCTGCCCGTTGGGAGTCTTCTTCATCCTAACAGGCACGTAGCCTTCGAAATCTTTGATCCCTCAACCCTTATGCTAAGCGAAGAATGTTTCAACACGTTTGGTCTTACTCTGCGCTTTGCAGAAGTGGACCTTACGCCTATATCTGACGTACTCCAGTGCAATATTTCCGGGTAGCCCGGCTAAGTATTCACAGACAAAGTAGGCTTATGGATGCATACAAGAGTCCACCGATCGGTCATTGTATGAAGCAAACTTGTGCGTCAAAGTTCATGAATAGTCACATAATGCAAATGCACCAAAGCATCTCGTAGCAATGTCTGATGAGTAGAATAGGGCGAGGGAGGGGCGCACCTACGGTTTCTAGTCAATGCAGTACAGAAGGAGGAATATGAGGACTCCTTGAGAGAGATGGTAAGGGTCTTTAGACTGAAGTATCTTTTGAAACCGCCATCGGCAGGTTATTCGCTACCGGAAGGGCGACGTAGAAACGTAGTTTCATGGGTAGTAACTGCATAAATAATCGTTCTAATAACCTCTGGAGATTACATTTCACTCCATGAATTGGTGCTGATAGGTGTGTAACCCCAGCAGAGGGTG\", \"GACTACGATCAAGTCAGGTCCCAGAGCCTAGCATTGTCCCTTTTAGCAGCTGCGAATAATAGACCGCTTGCCTTTATCTCCCCCCGTACGGGGCCTAGTGCAATGAAAACTAGGCTTAAGGACCCTCAGTAAACACCGGTGTCATATTACACGGGCTCAAGTCGGCTTGTCAGCCAAAAAGTACTGGGACTCGAGGCTGCTCTCAATCTAGCAACGTCGCTTCGCGATATTTACGAAATTCGTCCTAGTCACATGATGGCAAGCCATAAGCGTCGAGTTAAAACTACCACGCTTGTCTAGCGCCATTGCTGTCCATGATACATACAAGGTAGTTCCATTGCATTGACTGAATAGAACAGTCAACGGATTCTTTTGCGACCGGCGGACCTAGAGCATAGGAGGGAGTGTATCCAGAAGCCACCGCGTTCAGGTAGTGGTGAGGTTGCTATTACAAGCATGTTCGGTGGGAGGAGGATTGTTTCCACGAAACCACTCGCCCCTCAAGCCCCGGGAACGATGACTAGGTGGATCTAGACAGTCAGGGTAATCAGAGTACTGAAATACGGAACAAATAGAGGGGGACAATCATGGCGGCGGGAGAGCGTAGCTTACAGGTACCAGTTCACGGTTATTTCCAACATGGTGGCGCTAAAACTCACTCGCCTTGATTCTGTAGCTGCCGTCGCAAAACTGAACCGTTGCGAGATCAGTTATGGCGCATGAAATGTTGCATATGTTTATAAGCCGTCAACTGCAAGTCAAGACCAATTGTTACTTCCCCTCTGCGAGTCGACTCAAACAGAACAGTTCGCAGAGATAACCGTACAAGGCCGGATATTGGCACCCGGTTAAGCCATTGATGGGACTTATAAACGTCCTCTAACGCCACCCCCGCATACTGAATATTTTAAAGGGCGTTGACAACATCGAACGACCTGCTTTAGATAGCATTGATCTGGTGCTTGCATTTTTTTAA\"\r\n",
        "print(len(s1), len(s2))\r\n",
        "s, bt = lcs(s1, s2)\r\n",
        "lcs_output(bt, s1, len(s1), len(s2))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "917 976\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'CTACGATATCAGCCCAACCTAGATGCTTTTGCAGCGGAATGCCGTTGCCTATCGTACGGCTTCAATACTAGCTTAAGGACCCTCATACATGTCAATTACCCCAGTGGCGTACAATACTGGGCAGTGATTGCAATCGCTTCGCGATATTTGAAATTCGTCTGCCGATGGCAAGAAATCATAACTAAGCTTCTACGCATGTGTCATGATACTACGGTAGTCTTCTTACTAAAGACAGTCAAATCTTTGACCCACCTAGCTAAGGAGTGTTCAAAGCACCGCGTTCAGAGTGGATTGCTATACGAGTTCGTGAAATTTCCGGTAGCCCGGCTAAGTATTAGACAGTAGGTAATCAGAGTACGATCGGCATGAGACAAATGGCGCAAAGTTCATAAGTCACATAATGCAAATCACCGCATCTGTAGCTGTCGATGAGTAGAATAGGGCAGAGGCATAGTTTTAGTCAATGCAGTCAAGAAATTGACTCCTTGGAGGATAACAGACTGAAGATAACCGCAGGCGGTATTGCACCGGAAGGGGACTAAAACGTTCTAGACGCATAAATATTTTAATAACTCGAGATCTTTATCATGATTGGTGCTGATTTTAA'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Tcka-POGGAj",
        "outputId": "d8c948c0-307d-4ed8-bc45-a716ba7f26f6"
      },
      "source": [
        "s1,s2 = \"ACCGTCTTAGCGATCAACACATTTAACAACGCGCCGCACCCCCCGTCAAACGAGCTTTTGGGCTCTTGTCCTTTTACAAGCTTCACGACGCATACAGCCTTGATCAACGGTTTGATCTGTCTCCCTTCAGCTGGCTTTAAAGGACATACATATGAAGGCCTTAATAAGGTCCGGGAACTCCACATATTCGGTACTGGGCAAACCCCATGAACCACCTCAACATGAAGAGTCCGAGGACTCTCACGATCCACCAATGCAGATCGGAACTGTGCGATCGCGTAATGAGCCGAGTACTTGGTTTGTGTTTAGGTTATGGGGGCCGGGAGCCGGTTCAATATAAGGAAGTAGTTGCAGATTAGTTGTTGCGAACGGTCATAAATTTGATGGGTAAACGTGAACTTAACAAACCGTGATAGCTAATCCTATGCATCCCTTACGTGGATCGACTCGAGTACCCAGGTGAACCGACTACTTGATAACCGGAAATCGCGGTATAAAAGCGCTCACGGTCAGGAGATATACCTCCAAGCAGTAGTCTTTCTGAGCCTAGAGTAGTAAATTACAGGGACGATGTCTTTTACCGAGGCAACATTTTATTGAGAATCACATGAGGCACAGGTAAAGGCGACATCACGATCGAGATCAACCCCTACTTGTTCAAAACATTGAGAACCAGCTCTGTTTTGGAACCTAGAAAGATAACGCATCCGCTTGATATTCCACGGCTTGTCCCTCTTGTGCGGTCCATCTATCGGAGTTTCCTCCGATACGACCCGCAATGTTTCCAGGCGTACGGTACTTTATGAATACACTCGCGCTGTAACCTGTTATGTGAAACACACACGACAGAGCTTCGCGTGGGCCCAGCGACCCGGTAATACTACATCACCGCACACGACCTCGAGCAGTCTTTGCCGGCGTCCGTAAGTAGTCTAAAGTTGTGTTGATGCTTGGGGTTAAAGCTAAATCGTCCGCAGAATACGACTCTCATCCCAAT\",\"ACCCGCACGCGCTTTGGTCTAGATTCTAGCTCCAACTTGCCTGCTAGATACTCTGTTAAAAGATGGTTTTACAACCCCCTCCTCTGTCCCTGGGGTATTATATAATACGTCGGATAGTCAGGTACAAATACAAGTGGGTGGGAATACTTTTCCTCGGATCCTAGACCACGGATTACTGCGTGGTTGACAAGAGTCGGCCCGGAGGGAAACGTGAAGGTTAGTGCAATTAAAGTCTCTAATGTGAAGCCTCCGCGAAGCGAGGAGTTTCTGAGATCGAGTACTATTTAGAGTTCGAAATCACGGCTTAACCTCACTGCCACGCATAACTTGCCGGCAATCCAGTTTTGCAACGATACTTAATTTGTGCAGCTCATCTTTGCTGTCCAGAAATAGAGCTAGTCGATCTCATCTTGCGGGTAGCCAGAAGTCCTACCGTCTCCTCCATGTAGCTTAAAAATTTCGGTGAGGATCAAAAATGATAAACGTGACAGGTAAGCTCCTACGTCTATCCTATGACCCCCGCGGCAGAATAGGTTGGTAGTGTTAGTGCGTGAGCTGGTAGAATAGAGCACACTTAGGGAAACGGGAACCGTTATGTAGGGCTGCGACACACAAAAAAGTGTTCGTTGGTAAGCTGCCTCTCCACTAAACAGGATTTCTCTGGATGATCCCATCGAAGCAAGTTACGCACCACGCCGAGGCGGACCCTGGTACTAGCTGCCCCCCCCTTTATGGGGCGCTCGTACATCAAGATGATCGCGGACTCAACCTGATTACGAGTTGTCCAAGTAGTCCAGGGTAAGAGAAACTGGAGAGA\"\r\n",
        "s, bt = lcs(s1, s2)\r\n",
        "len(lcs_output(bt, s1, len(s1), len(s2)))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "573"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dOt9ujkLGxWp",
        "outputId": "4878f6ce-344d-4252-e20a-bd16f11d53e4"
      },
      "source": [
        "len(\"ACCGCAGCGTCAATTTACAACGCCGCACCGTAAAGATGGTTTTACAACCCCCTCCCTGTCCGGTTTATTTCTCTAGTCAGGACAAATAAAGTGGTGGGAATACTTTCTCGGACCAGACCACTACTGGTGGTTGACAAGAGTCGGCCCGGAGGGAACTGGTTGTGTTAGTTATGGGCCCCGGAAGGAGAGTTGAGATCGAGTCTATTTGAGTCGAATCACGGCTAACCTATGCACCTACTTGCCGATCCAGTGAACGATACTTATACCATCGCGTAAAAAGGCTAGTCGATATCCTCCAGAGTAGTCTTCTGAGCTAAAAATTCGGGAGATCAAAAATATAAACTGACAGGTAAGCCTACGTCATCAACCCCCGCAAAATTGGAGTGTTTTGGCTAGAAAGAGCACCTTGAAACGGGCCTTTGTGGGTCCACACAGTTTCTGTAAGCTGTTCCACTACGGTCTTATGATCATCGGCAAGTTAGCACCACGCGAGGCGGACCCGGTACTACTCCCCCACGCTCGACATCTTGCGGCTCCTGATTAAGTTGTGTGTCGGGTAAAGAAACTGAGAGA\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "573"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXtIg__gG29S",
        "outputId": "00fb4d15-45b2-47b0-c940-0f4c85f451f1"
      },
      "source": [
        "s1, s2 = \"GACT\",\"ATG\"\r\n",
        "s, bt = lcs(s1, s2)\r\n",
        "r = lcs_output(bt, s1, len(s1), len(s2))\r\n",
        "print(len(r), r)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2 AT\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5F7wtIH5HBSy",
        "outputId": "2373ed09-577d-4d8a-b38f-f7ee1378c901"
      },
      "source": [
        "s1, s2 = \"ATG\", \"GACT\"\r\n",
        "s, bt = lcs(s1, s2)\r\n",
        "print(s, bt)\r\n",
        "r = lcs_output(bt, s1, len(s1), len(s2))\r\n",
        "print(len(r), r)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 1. 1.]\n",
            " [0. 0. 1. 1. 2.]\n",
            " [0. 1. 1. 1. 2.]] [[0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 2. 2.]\n",
            " [0. 1. 1. 1. 0.]\n",
            " [0. 0. 1. 1. 1.]]\n",
            "2 AT\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cl3tOQgdHNx6",
        "outputId": "1c0fb5f2-0949-440a-9a5c-51761e60876d"
      },
      "source": [
        "s1, s2 = \"AGAGTAGACACCTTGCGCTCTGTTTGATATGGAAGCTCGCAGGTCCAGAGTGAAATCATAGAAATTACCATAAGCGATGATATGAAGCACAGATCACTGTTTGTGCTCAGTGGCATCGACTCTATTTAAACATAGTATACCGGTTTATTATAGGTCCTGTGCCTGGCCTCGTGTGCCGTGCCTTGGGATTTGAACGCTGAACTACCCACGCGCACGGAAGGGGTTCCAGTGCGCTAACAATAACACTGTATCCCAGTCGAGTCTGATCGCCCTAGAAAAGCAATTGCACTCAGGGAAACGTGCGGCGGCTCGGTCATCTCGATTGACGTGGGGTCCGCCGCTGAATTTAAAGACAGGCTATGATTGTTCCTTAACCGATCAAGCATGCGATTATTGGTCCCCTATACTCTATTACGTAATGCGGTGATCTGGTACTGGCAGCTGTCGATCTCGTGAATCTCCCGCTGCATTATTCGCCGTACTACCGAATGAGAGTGATCCCCGCCGGGCACTGCACCTGTGCGCCGGAGAATCGAGTTCATCACAACCACTGCTACAGACCTCTATAGACCGTAGACCGACCCCACGGTCCGTTATGAAGGAAGTCCAAAAGAGGCGGATGTCCTACGCTCTCTTCGCAGATCTATTCATACCTCCGGGTAAATTCTATGACAGCCCTACCACGGGATATGTACACTCTCACATGGAGATTTTTAGGTACAGATATTCATTGATGTACAATGGGCGGAGCGCCAGCGGACCGACCGAAATATCGAGTGTCGAGGATCAATCACGTTGCTACGTGCACCCGGCACCCGACAAATTCACGTGCAGCCGTCTCTTGGTAAGCGGGCACCGTCACGGATCGTGCGTGCCTAGCCTAGTGCCCGTGGGGCTATTGCTGGGGTATCCCCTTGGGAGAAGTTACGACGTTGATGATCCC\", \"CAGGAAGTGGTAGATAACCACTAGCTGACCAAGCAACCAGCATTCATACAACTTATTTAGGGAAGAGAAGGAGCAAGGTGTGGAGAAGTCATACCCCGTATGGATACGTTATTTGGGTCCAGAAATTAGTATAGGTGCCAACGAACAATTTCGATTCAATTAGATAGCGGTTCGCACCTCCTTCGGAGTGTGTGCGCAGCAGCTATCTTGCCCGCAGAAAGAACGCGGTGTCCCTGGGCTAACCGGGATGGTAAGCATTTTATAATCTGTGCACACGTCTATCATGAGACCTCTTCATGCCCGGTCGAAGGCGTAGGGATCAGCGGCTGGGATGGCCAAGTGCACGCCTTTTATGAGGGGATCCACTCTACTTGCGATCGCAACGTGCTGGGGTACGGCAACGTCCCCAGTAGGCTCGTTGCTGTACACGACTGCAGGTACTTGTTGAGGCAGGGCGCCCAATATAGTGGTCTGGACTCCGGCCCCATGATATTGATTATCACGTCATCGTGCCAACCTGAAACGGACTTTAGCTAGATGCTGGTCTGGTAGAATCAGAGATCTCCTTGTCCGTCTGTAAATCAGTGCAATCACGGAAATGTTGACACTATGTATGATAATCTGTTTCGAAACCGAACACGGTACACGGCTACGTACACTCGGTGTGTACATCAGCCTCAGCGCCCGAATCTCTGCGAAGATCAATCCTTGACCTCGGTGATACTTCGCTTAAATGTCGCGATACACAGCGTTCATAGAATAAGTAAACATACGCTGTAAGCTGGATAAGAAGAATTTTAGAAACTCAA\"\r\n",
        "s, bt = lcs(s1, s2)\r\n",
        "r = lcs_output(bt, s1, len(s1), len(s2))\r\n",
        "print(len(r), r)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "568 AGAGTAGACACTGCGCCAAGAACCGCATCATAAATATAGAAAAAAGCGTGTAGAAGCACAGATACGTTTTTGGGCAGATTATTTAAACAATTCGATTAATTGTGCGGTCGCCTCCTTGGGTTTGCGCGACTACCCCGCGAGAAGGGGTCCTGGCTAACATAACATTATCCCAGTCATCTGAGCCCTCATGCCCGGGAACGTGGGCGGCTGGATCCAAGTGCCGCCTTTTAGAGGGATCCTTACCGATCAAGCTGCGAAGTCCCCATACTCGTTGCGTACGACTGCAGGTACTTGTTGGCAGCGCCCAATAAGTGTCGGACTCCGGCCCAGAATGATTATCACCACTGCCAACCTCATAGCTAGAGCGGTCGTAGAATCAGAGATTCCTGTCTCTTAATCATCAATCCGGAAATTTGACACTAGTATGTAATCTCAAAGAAGGTACAGATACATTGTGTACATCAGCCCAGCGCCCGAATTCTGCGAGATCAATCCTTGCTCGTGAACCGCAAATTCCGTCAGCGTTCTGTAAGTACATCGCTGTAAGCTGGTAGGATTTAGAAACCAA\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "id": "ekVjwqSpLCdN",
        "outputId": "d71b1ed1-f3e1-4093-df3d-8f3cdf40a4e6"
      },
      "source": [
        "r"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'AGAGTAGACACTGCGCCAAGAACCGCATCATAAATATAGAAAAAAGCGTGTAGAAGCACAGATACGTTTTTGGGCAGATTATTTAAACAATTCGATTAATTGTGCGGTCGCCTCCTTGGGTTTGCGCGACTACCCCGCGAGAAGGGGTCCTGGCTAACATAACATTATCCCAGTCATCTGAGCCCTCATGCCCGGGAACGTGGGCGGCTGGATCCAAGTGCCGCCTTTTAGAGGGATCCTTACCGATCAAGCTGCGAAGTCCCCATACTCGTTGCGTACGACTGCAGGTACTTGTTGGCAGCGCCCAATAAGTGTCGGACTCCGGCCCAGAATGATTATCACCACTGCCAACCTCATAGCTAGAGCGGTCGTAGAATCAGAGATTCCTGTCTCTTAATCATCAATCCGGAAATTTGACACTAGTATGTAATCTCAAAGAAGGTACAGATACATTGTGTACATCAGCCCAGCGCCCGAATTCTGCGAGATCAATCCTTGCTCGTGAACCGCAAATTCCGTCAGCGTTCTGTAAGTACATCGCTGTAAGCTGGTAGGATTTAGAAACCAA'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SoRmbwIuxt9D"
      },
      "source": [
        "class Path:\r\n",
        "  def __init__(self, path):\r\n",
        "    self.path = path\r\n",
        "\r\n",
        "  def __repr__(self):\r\n",
        "    return \"->\".join(map(str,self.path))"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LpT4k9EELGHo"
      },
      "source": [
        "from collections import defaultdict\r\n",
        "\r\n",
        "class Graph:\r\n",
        "\r\n",
        "  def __init__(self):\r\n",
        "    self.adjacency = defaultdict(dict)\r\n",
        "    self.all_nodes = set()\r\n",
        "\r\n",
        "  def connect(self, a, b, w):\r\n",
        "    self.adjacency[a][b] = w\r\n",
        "    self.all_nodes.add(a)\r\n",
        "    self.all_nodes.add(b)\r\n",
        "\r\n",
        "  def __topological_dfs(self, current, stack, visited):\r\n",
        "    if current in visited:\r\n",
        "      return stack\r\n",
        "    visited.add(current)\r\n",
        "    neighboors = self.adjacency[current].keys()\r\n",
        "    for node in neighboors:\r\n",
        "      self.__topological_dfs(node, stack, visited)\r\n",
        "    stack.append(current)\r\n",
        "    return stack\r\n",
        "\r\n",
        "  # unfortunately, there is no need for all N to be on the [0,...,N-1] interval :(  \r\n",
        "  def __max_nodes_required(self):\r\n",
        "    return (max(self.all_nodes) + 1)\r\n",
        "\r\n",
        "\r\n",
        "  def components(self):\r\n",
        "    components = [0] * self.__max_nodes_required()\r\n",
        "    for i in self.all_nodes:\r\n",
        "      components[i] = i\r\n",
        "    # can be implemented faster with references, this is O(n^3)\r\n",
        "    for i in self.all_nodes:\r\n",
        "      for j in self.adjacency[i].keys():\r\n",
        "        for k in self.all_nodes:\r\n",
        "          if components[k] == j:\r\n",
        "            components[k] = components[i]\r\n",
        "    return components\r\n",
        "\r\n",
        "  def component_containing(self, key):\r\n",
        "    components = self.components()\r\n",
        "    component = {i for i in self.all_nodes if components[i] == components[key]}\r\n",
        "    return component\r\n",
        "\r\n",
        "  def __longest_paths(self, starting: int):\r\n",
        "    component = self.component_containing(starting)\r\n",
        "    topological = self.topological()\r\n",
        "    topological_on_path = [i for i in topological if i in component]\r\n",
        "    max_distance = [0] * self.__max_nodes_required()\r\n",
        "    previous = [-1] * self.__max_nodes_required()\r\n",
        "    appeared = False\r\n",
        "    for a in topological:\r\n",
        "      if a == starting:\r\n",
        "        appeared = True\r\n",
        "      if a in component and appeared:\r\n",
        "        for b, w in self.adjacency[a].items():\r\n",
        "          new_distance = max_distance[a] + w\r\n",
        "          if new_distance > max_distance[b]:\r\n",
        "            max_distance[b] = new_distance\r\n",
        "            previous[b] = a\r\n",
        "    return max_distance, previous\r\n",
        "\r\n",
        "  # DFS implementation, nasty...\r\n",
        "  def longest_path_to(self, starting: int, ending: int):\r\n",
        "    max_distance, previous = self.__longest_paths(starting)\r\n",
        "    return self.__recreate_longest_path(starting, max_distance, previous, ending)\r\n",
        "\r\n",
        "  def __recreate_longest_path(self, starting: int, max_distance: List, previous: List, ending: int):\r\n",
        "    path = [ending]\r\n",
        "    current = ending\r\n",
        "    while current != starting:\r\n",
        "      current = previous[current]\r\n",
        "      path.append(current)\r\n",
        "    path = list(reversed(path))\r\n",
        "    return max_distance[ending], Path(path)\r\n",
        "\r\n",
        "\r\n",
        "  # DFS implementation, nasty...\r\n",
        "  def longest_path(self, starting: int):\r\n",
        "    max_distance, previous = self.__longest_paths(starting)\r\n",
        "    ending = np.argmax(max_distance)\r\n",
        "    return self.__recreate_longest_path(starting, max_distance, previous, ending)\r\n",
        "\r\n",
        "\r\n",
        "  def topological(self):\r\n",
        "    stack = []\r\n",
        "    visited = set()\r\n",
        "    for i in self.all_nodes:\r\n",
        "      self.__topological_dfs(i, stack, visited)\r\n",
        "    return list(reversed(stack))\r\n",
        "\r\n",
        "  def __repr__(self):\r\n",
        "    return f\"{self.all_nodes}:::{self.adjacency.__repr__()}\""
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3pzlkx0mOXt"
      },
      "source": [
        "def adjancecy_string_to_graph(adj_string: str):\r\n",
        "  graph = Graph()\r\n",
        "  for line in adj_string.split(\"\\n\"):\r\n",
        "    a = int(line.split(\"->\")[0])\r\n",
        "    b = int(line.split(\"->\")[1].split(\":\")[0])\r\n",
        "    w = int(line.split(\":\")[1])\r\n",
        "    graph.connect(a, b, w)\r\n",
        "  return graph"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I5odGE9dnD36",
        "outputId": "77a40829-24d4-4c90-930e-a8d7e4bc3630"
      },
      "source": [
        "g = adjancecy_string_to_graph(\"\"\"0->1:7\r\n",
        "0->2:4\r\n",
        "2->3:2\r\n",
        "1->4:1\r\n",
        "3->4:3\r\n",
        "5->6:10\"\"\")\r\n",
        "g"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0, 1, 2, 3, 4, 5, 6}:::defaultdict(<class 'dict'>, {0: {1: 7, 2: 4}, 2: {3: 2}, 1: {4: 1}, 3: {4: 3}, 5: {6: 10}})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZ_xdDo0nF3K",
        "outputId": "17ef0367-78ec-4619-f4ca-a41a4a3631b5"
      },
      "source": [
        "g.topological()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[5, 6, 0, 2, 3, 1, 4]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcKqBNOFoewT",
        "outputId": "ac4f99f6-5014-4db0-ec8f-1b7cd83214c0"
      },
      "source": [
        "g.component_containing(0)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0, 1, 2, 3, 4}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o9TnY64ApFpj",
        "outputId": "4c48f511-e1f1-4ca7-bee3-9190686908d4"
      },
      "source": [
        "g.longest_path_to(0, 4)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9, 0->2->3->4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S9f8rjJxt_jq",
        "outputId": "230c7dfb-c588-4a78-ef19-5b483017efc0"
      },
      "source": [
        "g = adjancecy_string_to_graph(\"\"\"0->6:11\r\n",
        "6->12:11\r\n",
        "12->30:1\r\n",
        "30->49:10\r\n",
        "7->47:3\r\n",
        "15->42:19\r\n",
        "48->49:20\r\n",
        "42->49:9\r\n",
        "23->43:1\r\n",
        "18->42:4\r\n",
        "37->42:2\r\n",
        "38->47:2\r\n",
        "28->41:15\r\n",
        "18->33:10\r\n",
        "0->42:6\r\n",
        "1->49:16\r\n",
        "16->31:18\r\n",
        "32->35:4\r\n",
        "26->44:10\r\n",
        "7->40:11\r\n",
        "25->28:15\r\n",
        "34->41:1\r\n",
        "31->42:5\r\n",
        "25->42:17\r\n",
        "17->34:10\r\n",
        "22->27:13\r\n",
        "17->22:16\r\n",
        "19->35:15\r\n",
        "24->35:18\r\n",
        "36->47:19\r\n",
        "25->49:18\r\n",
        "15->29:15\r\n",
        "17->21:6\r\n",
        "10->33:6\r\n",
        "0->47:14\r\n",
        "5->20:2\r\n",
        "7->43:4\r\n",
        "40->41:13\r\n",
        "12->35:16\r\n",
        "30->42:4\r\n",
        "16->39:2\r\n",
        "24->48:2\r\n",
        "23->31:7\r\n",
        "16->20:4\r\n",
        "20->29:19\r\n",
        "46->49:4\r\n",
        "5->28:12\r\n",
        "25->37:7\r\n",
        "35->41:11\r\n",
        "45->47:1\r\n",
        "14->15:14\r\n",
        "0->35:7\r\n",
        "11->32:12\r\n",
        "36->41:12\r\n",
        "3->27:11\r\n",
        "29->40:17\r\n",
        "22->33:8\r\n",
        "19->23:20\r\n",
        "21->30:11\r\n",
        "33->44:15\r\n",
        "17->47:9\r\n",
        "8->26:13\r\n",
        "18->19:14\r\n",
        "3->40:12\r\n",
        "46->47:19\r\n",
        "41->47:16\r\n",
        "13->31:18\r\n",
        "1->18:8\r\n",
        "32->41:2\r\n",
        "32->38:13\r\n",
        "11->16:18\r\n",
        "27->49:3\r\n",
        "44->49:9\r\n",
        "4->41:16\r\n",
        "13->15:17\r\n",
        "39->41:2\r\n",
        "10->32:9\r\n",
        "37->39:16\r\n",
        "3->16:4\r\n",
        "8->28:2\r\n",
        "4->23:20\r\n",
        "41->48:16\r\n",
        "18->28:15\r\n",
        "14->34:12\r\n",
        "18->44:18\r\n",
        "7->8:12\r\n",
        "31->41:11\r\n",
        "5->49:9\r\n",
        "0->26:16\r\n",
        "38->42:16\r\n",
        "0->1:7\r\n",
        "1->3:18\r\n",
        "3->4:15\r\n",
        "4->5:19\r\n",
        "5->7:10\r\n",
        "7->10:17\r\n",
        "10->11:8\r\n",
        "11->13:8\r\n",
        "13->14:12\r\n",
        "14->17:12\r\n",
        "17->24:16\r\n",
        "24->25:14\r\n",
        "25->36:18\r\n",
        "36->45:16\r\n",
        "45->46:15\"\"\")\r\n",
        "g.longest_path_to(0, 49)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(222, 0->1->3->4->5->7->10->11->13->14->17->24->25->36->41->48->49)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 155
        },
        "id": "xvI6j1i4GkGq",
        "outputId": "d6e29d36-be70-4471-c006-47fc79223a6a"
      },
      "source": [
        "s, bt = lcs(\"GCGATC\", \"CTGACG\")\r\n",
        "print(bt)\r\n",
        "lcs_output(bt, \"GCGATC\", len(\"GCGATC\"), len(\"CTGACG\"))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 1. 0. 2. 2. 2.]\n",
            " [0. 0. 2. 1. 1. 0. 2.]\n",
            " [0. 1. 1. 0. 2. 1. 0.]\n",
            " [0. 1. 1. 1. 0. 2. 1.]\n",
            " [0. 1. 0. 1. 1. 1. 1.]\n",
            " [0. 1. 1. 1. 1. 0. 2.]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'CGAC'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 155
        },
        "id": "VWESglp5vkpW",
        "outputId": "6433fae4-2d3b-4e84-d247-ba4be9895307"
      },
      "source": [
        "s, bt = lcs(\"CTCGAT\", \"TACGTC\")\r\n",
        "print(bt)\r\n",
        "lcs_output(bt, \"CTCGAT\", len(\"CTCGAT\"), len(\"TACGTC\")) "
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 1. 0. 2. 2. 2.]\n",
            " [0. 0. 2. 1. 1. 0. 2.]\n",
            " [0. 1. 1. 0. 2. 1. 0.]\n",
            " [0. 1. 1. 1. 0. 2. 1.]\n",
            " [0. 1. 0. 1. 1. 1. 1.]\n",
            " [0. 1. 1. 1. 1. 0. 2.]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'TCGT'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "buzsGz1wGqe6"
      },
      "source": [
        "from itertools import combinations_with_replacement\r\n",
        "from itertools import permutations\r\n",
        "def combinations_for_masses(m1, m2, target):\r\n",
        "  possibles = 0\r\n",
        "  for length in range(math.ceil(target / min(m1,m2)) + 1):\r\n",
        "    for comb in combinations_with_replacement([m1, m2], length):\r\n",
        "      if sum(comb) == target:\r\n",
        "        print(comb)\r\n",
        "        # very slow, could be optimized because we only need the number\r\n",
        "        possibles += len(set(permutations(comb)))\r\n",
        "  return possibles"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D9S8Z5AwHrmb",
        "outputId": "393d8069-de71-4ef6-ffdd-142b67eb19f7"
      },
      "source": [
        "combinations_for_masses(2,5,10)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5, 5)\n",
            "(2, 2, 2, 2, 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdgbstKcHwU6"
      },
      "source": [
        "# combinations_for_masses(2,3,25)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVJ-QxJEadma"
      },
      "source": [
        "# combinations_for_masses(2,3,22)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEtxQE7oIGq6",
        "outputId": "6fa1d2b4-cf52-4e3a-a6d0-409b9d89919b"
      },
      "source": [
        "g = adjancecy_string_to_graph(\"\"\"1->2:0\r\n",
        "1->3:0\r\n",
        "1->4:0\r\n",
        "1->5:0\r\n",
        "1->6:0\r\n",
        "2->3:0\r\n",
        "2->6:0\r\n",
        "3->4:0\r\n",
        "5->4:0\r\n",
        "5->6:0\"\"\")\r\n",
        "g.topological() == [1, 5, 2, 6, 3, 4]"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CsaoBprYKAVr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1fe6c9d-5e33-45c1-95f0-c72240018404"
      },
      "source": [
        "import re\r\n",
        "\r\n",
        "def read_cost_table(name):\r\n",
        "  uri = f\"https://raw.githubusercontent.com/guilhermesilveira/bioinformatics/main/{name}.txt\"\r\n",
        "  data = read_uri(uri)\r\n",
        "  headers = re.split(\"\\s+\", data[0])\r\n",
        "  costs = defaultdict(dict)\r\n",
        "  for line in data[1:]:\r\n",
        "    line_data = re.split(\"\\s+\", line)\r\n",
        "    line_name = line_data[0]\r\n",
        "    for i, col_value in enumerate(line_data[1:]):\r\n",
        "      col_name = headers[i]\r\n",
        "      costs[line_name][col_name] = int(col_value)\r\n",
        "  return costs\r\n",
        "\r\n",
        "read_cost_table(\"BLOSUM62\")['A']['A'] == 4"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncvnruwYFiWd"
      },
      "source": [
        "class CostPath:\r\n",
        "\r\n",
        "  def __init__(self, first, second, backtrack, x = None, y = None):\r\n",
        "    self.backtrack = backtrack\r\n",
        "    self.first= first\r\n",
        "    self.second = second\r\n",
        "    self.start_x = x\r\n",
        "    if x == None:\r\n",
        "      self.start_x = len(self.first.code)\r\n",
        "    self.start_y = y\r\n",
        "    if y == None:\r\n",
        "      self.start_y = len(self.second.code)\r\n",
        "\r\n",
        "  def __repr__(self):\r\n",
        "    return self.__output(self.backtrack, self.start_x, self.start_y)\r\n",
        "\r\n",
        "  def __output(self,backtrack, i, j):\r\n",
        "    first_stack = \"\"\r\n",
        "    second_stack = \"\"\r\n",
        "    while (i != 0 or j != 0):\r\n",
        "      # print(i, j, backtrack[i,j])\r\n",
        "      if backtrack[i, j] == 1:\r\n",
        "        first_stack += self.first.code[i-1]\r\n",
        "        second_stack += \"-\"\r\n",
        "        i -= 1\r\n",
        "      elif backtrack[i, j] == 2:\r\n",
        "        second_stack += self.second.code[j-1]\r\n",
        "        first_stack += \"-\"\r\n",
        "        j -= 1\r\n",
        "      elif backtrack[i, j] == 0:\r\n",
        "        first_stack += self.first.code[i-1]\r\n",
        "        second_stack += self.second.code[j-1]\r\n",
        "        i -= 1\r\n",
        "        j -= 1\r\n",
        "      else:\r\n",
        "        i = 0\r\n",
        "        j = 0\r\n",
        "    return \"\".join(reversed(first_stack)) + \"\\n\" + \"\".join(reversed(second_stack))\r\n"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0pgfZuJBsvt"
      },
      "source": [
        "from typing import Dict\r\n",
        "\r\n",
        "class Peptide:\r\n",
        "\r\n",
        "\r\n",
        "  def __init__(self, code):\r\n",
        "    self.code = code\r\n",
        "\r\n",
        "\r\n",
        "  def global_alignment(self, other_peptide, cost_matrix: Dict, indel_penalty=5):\r\n",
        "    # can be optimized to use only 2 lines if no backtrack is required\r\n",
        "    li = len(self.code)\r\n",
        "    lj = len(other_peptide.code)\r\n",
        "    scores = np.zeros((li+1, lj+1))\r\n",
        "    for i in range(1, lj+1):\r\n",
        "      scores[0,i] = scores[0,i-1] - indel_penalty\r\n",
        "    for i in range(1, li+1):\r\n",
        "      scores[i,0] = scores[i-1, 0] -indel_penalty\r\n",
        "    backtrack = np.zeros(scores.shape)\r\n",
        "    backtrack[0,:] = 2\r\n",
        "    backtrack[:,0] = 1\r\n",
        "    for i in range(1, li + 1):\r\n",
        "      for j in range(1, lj + 1):\r\n",
        "        from_top = scores[i-1,j] - indel_penalty\r\n",
        "        from_left = scores[i,j-1] - indel_penalty\r\n",
        "        extra_cost = cost_matrix[self.code[i-1]][other_peptide.code[j-1]]\r\n",
        "        from_diagonal = scores[i-1,j-1] + extra_cost\r\n",
        "        scores[i, j] = max(from_top, from_left, from_diagonal)\r\n",
        "        # print(i, j, scores[i,j], from_top, from_left, from_diagonal, extra_cost, self.code[i-1], other_peptide.code[j-1])\r\n",
        "        if scores[i, j] == from_top:\r\n",
        "            backtrack[i, j] = 1\r\n",
        "        elif scores[i, j] == from_left:\r\n",
        "            backtrack[i, j] = 2\r\n",
        "        else:\r\n",
        "            backtrack[i, j] = 0\r\n",
        "    return scores, CostPath(self, other_peptide, backtrack)\r\n",
        "\r\n",
        "  def local_alignment(self, other_peptide, cost_matrix: Dict, indel_penalty=5):\r\n",
        "    li = len(self.code)\r\n",
        "    lj = len(other_peptide.code)\r\n",
        "    scores = np.zeros((li+1, lj+1))\r\n",
        "    backtrack = np.zeros(scores.shape)\r\n",
        "    backtrack[0,:] = 2\r\n",
        "    backtrack[:,0] = 1\r\n",
        "    for i in range(1, li + 1):\r\n",
        "      for j in range(1, lj + 1):\r\n",
        "        from_beginning = 0\r\n",
        "        from_top = scores[i-1,j] - indel_penalty\r\n",
        "        from_left = scores[i,j-1] - indel_penalty\r\n",
        "        extra_cost = cost_matrix[self.code[i-1]][other_peptide.code[j-1]]\r\n",
        "        from_diagonal = scores[i-1,j-1] + extra_cost\r\n",
        "        scores[i, j] = max(from_top, from_left, from_diagonal, from_beginning)\r\n",
        "        # print(i, j, scores[i,j], from_top, from_left, from_diagonal, from_beginning, extra_cost, self.code[i-1], other_peptide.code[j-1])\r\n",
        "        if scores[i, j] == from_top:\r\n",
        "            backtrack[i, j] = 1\r\n",
        "        elif scores[i, j] == from_left:\r\n",
        "            backtrack[i, j] = 2\r\n",
        "        elif scores[i, j] == from_diagonal:\r\n",
        "            backtrack[i, j] = 0\r\n",
        "        else:\r\n",
        "            backtrack[i, j] = 3\r\n",
        "    x, y = np.unravel_index(scores.argmax(), backtrack.shape)\r\n",
        "    return scores, CostPath(self, other_peptide, backtrack, x, y)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LeB9n3-V2nIY",
        "outputId": "28d9ccdf-fd25-4d42-e424-345845f81c07"
      },
      "source": [
        "scores, path = Peptide(\"MEANLY\").local_alignment(Peptide(\"PENALTY\"), read_cost_table(\"PAM250\"))\r\n",
        "print(scores)\r\n",
        "print(path.backtrack)\r\n",
        "print(path)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0.  0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  4.  0.  0.]\n",
            " [ 0.  0.  4.  1.  0.  0.  4.  0.]\n",
            " [ 0.  1.  0.  4.  3.  0.  1.  1.]\n",
            " [ 0.  0.  2.  2.  4.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0. 10.  5.  0.]\n",
            " [ 0.  0.  0.  0.  0.  5.  7. 15.]]\n",
            "[[1. 2. 2. 2. 2. 2. 2. 2.]\n",
            " [1. 3. 3. 3. 3. 0. 3. 3.]\n",
            " [1. 3. 0. 0. 0. 3. 0. 3.]\n",
            " [1. 0. 0. 0. 0. 3. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 3.]\n",
            " [1. 3. 3. 3. 0. 0. 2. 2.]\n",
            " [1. 3. 3. 3. 3. 1. 0. 0.]]\n",
            "EANL-Y\n",
            "ENALTY\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "duEO0eU412Kq",
        "outputId": "812bd66d-e2ed-4054-88b9-0f7b513571d3"
      },
      "source": [
        "scores, path = Peptide(\"CGA\").local_alignment(Peptide(\"G\"), read_cost_table(\"PAM250\"))\r\n",
        "print(scores)\r\n",
        "print(path.backtrack)\r\n",
        "print(path)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0.]\n",
            " [0. 0.]\n",
            " [0. 5.]\n",
            " [0. 1.]]\n",
            "[[1. 2.]\n",
            " [1. 3.]\n",
            " [1. 0.]\n",
            " [1. 0.]]\n",
            "CG\n",
            "-G\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qdQcSzr_7gQZ",
        "outputId": "2c15056d-d3a1-44cd-94fb-2d88511f7d67"
      },
      "source": [
        "scores, path = Peptide(\"THFEREYATHNCPPKIPLGYGNHVRNKGMIVHYANIGSFMLVRWVIGMWKCGENPCGASVTRVSVVHHEQDDPLCYDSKFSQKKLETYHCDHGHSIYVKYQLMWIKWDFWERQSRACEESCVCRPSSIILCAKQSDSQLDNATYSRPKIITCNRCNIVGHPKPYCSIMQIWAQRFFCYDIVAKYMVHAEEKYYTESPSAFINYHDSIRTPHQRTSMMCLGQNWYMNNWTDTGIEAAWQFGLELMKCLWDSHSNAFEQQNAKGRQGYDYRFDVNEPARHASKDKSGNRHVYCLQKIMRKWWDTAKCYIQPHWTKPTASVLPAIITLFYWNDKRKTMHTFLNFGGNLTMWYRGAICSWCFTTHIRAYLYYAAGAYAAGNGCSHTSEWAVHRVSRLSNEDMLYEGMRLAVKYYQICDLDTSRNCMCPVQGQPWMSRKIGGVAMDRWPDGCKQCPDVAPHVDALRQTECLEFRELHLAGMKIWKWDRCYNYSWADPMIVNYADSYLQMHIHPVNVDGHCQKVTILWYLSAVEIQWQINDHPRCKVMAALIILWMENLIFRPIHVYVHVMCHMHDGRQETAMTSHIENFCKNDSCRETRTDFMGRVRMGAKQGYPYWIHEHQAWNFKSSWFRCLIKGIMVMGDKQKDNCVCELMGQEHNVLGVVKYMDMMCVIQSAILNASPRHYAENFNIMNEYSAMQTTMLSPKLVFASRNKTTSEAAGNQSNHKIVQSRCHVRMSDLPIGISRYPCSWIKQITNMLVHQIFSQSINLRGMQWVTAEVNVAFVPQIQALIWEKESAQPWFPTMHWGIPWTFTAVNCMWVYLRYNKLRDHQVHAATSVLEEVYHVYQWEAEHEVMGRYGHWNKLFANNHRMRDCVQLPDRPGVVYPHEMINRQDSMICLEPMHP\").local_alignment(Peptide(\"QGIAEWKTRIVMRHIMLARHPIEETPMSFYYYIMLAVSCNPNDANWYIDFNCDVSFQDDSDASRPGCRGMAFAENLYSGGWIWITMHGCVRGWEDWRQEEMRQWYQQTVFKTWLSLGADSYCWTKYFGWVKEATPNEVVPTMYFWFRKPIEGTPDWFWIMKVNVPRSIACAWLYSMGHEPFSDRDDSVDCWSQLRVYCKGVPYCYDAFDQEAVTVRAIPRCPMWYTPMDQYPEVMSWRFMKHDDICEKNMYCCMYHLRTEVTLWDSPSNTGNQVFWHVFEQTNAKGSQGYDYRFDVDEQIAAVDVFHNHVYCWWDTAKYYIQPHWTASVLPAIITLFYWNATRKWLMHTFLNFGGNLTMWYRGAICSWCQTTHIRAYLYAAAIEAYAGNGCSHTSEWAVHRVSRHRDNRSNEDMMKLDPFYEGMRLAVKYYGCQICRLDTSRNCKCPVEWKIGGVAMDRWVDGCKQCPDALVQTAQYFHYWKWDRCGGNMDCPNQMHIQWKVNWWQYGHCKKVTIEWYLQWQINDHPRDIPAEYKVMAALIILWMENLEGRKQHLNYAYNRKTDICWYINTHYVHVHMHRGRQYICHITTVDTAMTSHVHNFCKNDVCRSQDLCLTLCTRPVASRGLQGIYKNGEKSEGNFGWSWLCIEFIFEMSPFECQWGMPNASKPDFWARQGPWMFYHMEEWNQDIFCRHHAHPGVTPNFHEWYPRPRKSTQEIQVTIVETEMQGNKTHIHYSTRFMFIVGYNDKLANFNEYQQNDMIWFNCSARVTLKPNHHAQHGFCSGLWWWPFLPCKGVNTNCAMFSACAPFGYPPVSPVTIHNCENRPHSTRVYEHFYTPYVLQSTHKIALERSTSCIYHRLQQSTGVIWHRFNSIVDQSLAWQCFLCASWPHQCAVDLKWWWDITFMCTVTKTPDSQGGC\"), read_cost_table(\"PAM250\"))\r\n",
        "print(scores)\r\n",
        "print(path.backtrack)\r\n",
        "print(path)\r\n",
        "print(scores.max())"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[   0.    0.    0. ...    0.    0.    0.]\n",
            " [   0.    0.    0. ...    0.    0.    0.]\n",
            " [   0.    3.    0. ...    0.    0.    0.]\n",
            " ...\n",
            " [   0.    0.    0. ... 1054. 1049. 1053.]\n",
            " [   0.    3.    0. ... 1061. 1056. 1051.]\n",
            " [   0.    0.    3. ... 1066. 1061. 1056.]]\n",
            "[[1. 2. 2. ... 2. 2. 2.]\n",
            " [1. 3. 0. ... 0. 0. 3.]\n",
            " [1. 0. 3. ... 3. 3. 3.]\n",
            " ...\n",
            " [1. 3. 3. ... 2. 1. 1.]\n",
            " [1. 0. 3. ... 2. 2. 2.]\n",
            " [1. 0. 0. ... 0. 2. 2.]]\n",
            "YATHNCPPKIPLGYGNHVRN--KGMIVHYANIGSFMLVRWVIGMWKCGENPCGASVTRVSVVHHEQDDPLCYDSKFSQKKLETYHCDHGHSIYVKYQLMWIKWDF-WERQSRACEESCVCRPSSIILCAKQSDSQLD---NATYSRPKIITCNR-CNIVGHPKPYCSIMQ-I--WAQ-RFFCYDIVAKYMVHAEEKYYTES-PS-A--F--IN-YHDSIRTPHQRTSMMCLGQNWY--MNNWTDTGIEAAWQFGLEL-MKCLWDSHSNAFEQQNAKGRQGYDYRFDVNEPARHASKDKSGNRHVYCLQKIMRKWWDTAKCYIQPHWTKPTASVLPAIITLFYWNDKRK-TMHTFLNFGGNLTMWYRGAICSWCFTTHIRAYLYYAA-GAYAAGNGCSHTSEWAVHRVSRL----SNEDM--L---YEGMRLAVKYY--QICDLDTSRNCMCPVQGQPWMSRKIGGVAMDRWPDGCKQCPDVAPHVDALRQTECLEFRELHLAGMKIWKWDRCYNYSWADPMIVNYADSYLQMHIH-PVNV-D-GHCQKVTILWYLSAVEIQWQINDHPR-----CKVMAALIILWMENL------I-F---RPIHV--YV--H-VMCHMHDGRQ--------ETAMTSHIENFCKNDSCRETRTDF-MGR-VR-MGAK--QGYPYWIHEH-QAWNFKSSWFRCLIKGIMVMGDKQKDNCVCELMGQEHNVLGVVKYMDMMCVIQSAILNASPRHYAENFNIMNEYSAMQTTMLSPKLVFASRNKTTSEAAGNQSNHKIVQSRCHVRMSDLPIGISRYPCSWIKQITNMLVHQIFSQSINLRGMQWVTAEVNVAFVPQIQALIWEKESAQPWFPTMH-WGIPWTFTAV-N-CM-WVYLRYNKLRDH--QVHA-ATSVLEEVYHVYQWEAEHEV-MGRYGHWNKLFANNHRMRDCVQLP-DR-PGVVYPHEMINRQDSMIC\n",
            "YIDFNCDVSFQDD-SDASRPGCRGM-A-FAE-NLYS-GGW-I--WI-TMHGC---V-RGWEDWR-QEE-MR-QW-YQQTVFKTWLS-LGADSY--C---WTKY-FGWVKEATP-NEV-V--PTMYFWFRKPIEGTPDWFWIMKVNVPRSIACAWLYSM-GH-EPFSDRDDSVDCWSQLRVYCKGVPYCYDAFDQEAVTVRAIPRCPMWYTPMDQYPEVMSWRFMKHDDIC-EKNMYCCMYHLR-TEV-TLWDSPSNTGNQVFW--H--VFEQTNAKGSQGYDYRFDVDEQI--AAVDVF-HNHVYC-------WWDTAKYYIQPHWT---ASVLPAIITLFYWNATRKWLMHTFLNFGGNLTMWYRGAICSWCQTTHIRAYLYAAAIEAYA-GNGCSHTSEWAVHRVSRHRDNRSNEDMMKLDPFYEGMRLAVKYYGCQICRLDTSRNCKCPVE---W---KIGGVAMDRWVDGCKQCPD-A--L--V-QTA--QY--FHY-----WKWDRC---G-GN-M--DCPN---QMHIQWKVNWWQYGHCKKVTIEWYL-----QWQINDHPRDIPAEYKVMAALIILWMENLEGRKQHLNYAYNRKTDICWYINTHYVHVHMHRGRQYICHITTVDTAMTSHVHNFCKNDVCR-SQ-DLCLTLCTRPVASRGLQGI-YKNGEKSEG-NFGWSWL-C-IEFIFEMS--PFE-C--QW-GM-PNA-SKPDFWARQ-G-PWMFYHMEEWN-QDIF-CRHH--A-HPGV-TPN--FHEWYPRPRKST-QEIQVTIVETEMQGNKTHIHYS-TRFM--FIVGYNDKLAN--FNE-YQQNDMIWFNCSARVTLKPNHHAQH-GFCSGLWWWPFLPCKGVN-TNCAMFSACAPFGYPPVSPVTIHNCENRPHSTRVYEHFYTPYVLQSTHKIALER-ST-SCIY---HRLQQSTGVIWHRFNSIV-DQSL-AWQ-CFLC\n",
            "1097.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EV7E0XR7teRz",
        "outputId": "5ce72a7a-6031-4173-b6d6-d5b2938a0c6c"
      },
      "source": [
        "scores, path = Peptide(\"CGA\").global_alignment(Peptide(\"G\"), read_cost_table(\"BLOSUM62\"))\r\n",
        "print(scores)\r\n",
        "print(path.backtrack)\r\n",
        "print(path)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  0.  -5.]\n",
            " [ -5.  -3.]\n",
            " [-10.   1.]\n",
            " [-15.  -4.]]\n",
            "[[1. 2.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 1.]]\n",
            "3 1 1.0\n",
            "2 1 0.0\n",
            "1 0 1.0\n",
            "CGA\n",
            "-G-\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0TDu8byut4Ex",
        "outputId": "89e270ca-4fdb-4b61-edae-b534bed5dd43"
      },
      "source": [
        "scores, path = Peptide(\"G\").global_alignment(Peptide(\"CGA\"), read_cost_table(\"BLOSUM62\"))\r\n",
        "print(scores)\r\n",
        "print(path.backtrack)\r\n",
        "print(path)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  0.  -5. -10. -15.]\n",
            " [ -5.  -3.   1.  -4.]]\n",
            "[[1. 2. 2. 2.]\n",
            " [1. 0. 0. 2.]]\n",
            "1 3 2.0\n",
            "1 2 0.0\n",
            "0 1 2.0\n",
            "-G-\n",
            "CGA\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qeqib2m8pSl0",
        "outputId": "dd2fc0ed-5dde-4270-b23e-58df02b0f44e"
      },
      "source": [
        "scores, path = Peptide(\"G\").global_alignment(Peptide(\"ACATACGATG\"), read_cost_table(\"BLOSUM62\"))\r\n",
        "print(scores)\r\n",
        "print(path.backtrack)\r\n",
        "print(path)\r\n",
        "print(scores[-1][-1])"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  0.  -5. -10. -15. -20. -25. -30. -35. -40. -45. -50.]\n",
            " [ -5.   0.  -5. -10. -15. -20. -25. -24. -29. -34. -39.]]\n",
            "[[1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.]\n",
            " [1. 0. 2. 2. 2. 2. 2. 0. 2. 2. 2.]]\n",
            "1 10 2.0\n",
            "1 9 2.0\n",
            "1 8 2.0\n",
            "1 7 0.0\n",
            "0 6 2.0\n",
            "0 5 2.0\n",
            "0 4 2.0\n",
            "0 3 2.0\n",
            "0 2 2.0\n",
            "0 1 2.0\n",
            "------G---\n",
            "ACATACGATG\n",
            "-39.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5n6psHkroit",
        "outputId": "12a07616-0acc-4f9e-ad9c-9009d964b2e8"
      },
      "source": [
        "scores, path = Peptide(\"ACT\").global_alignment(Peptide(\"ACG\"), read_cost_table(\"BLOSUM62\"))\r\n",
        "print(scores)\r\n",
        "print(path.backtrack)\r\n",
        "print(path)\r\n",
        "print(scores[-1][-1])"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  0.  -5. -10. -15.]\n",
            " [ -5.   4.  -1.  -6.]\n",
            " [-10.  -1.  13.   8.]\n",
            " [-15.  -6.   8.  11.]]\n",
            "[[1. 2. 2. 2.]\n",
            " [1. 0. 2. 2.]\n",
            " [1. 1. 0. 2.]\n",
            " [1. 1. 1. 0.]]\n",
            "3 3 0.0\n",
            "2 2 0.0\n",
            "1 1 0.0\n",
            "ACT\n",
            "ACG\n",
            "11.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zsBoGWG-sySY",
        "outputId": "956160ee-63c9-4e40-85d2-a1bf6dafbf6c"
      },
      "source": [
        "scores, path = Peptide(\"AG\").global_alignment(Peptide(\"AT\"), read_cost_table(\"BLOSUM62\"))\r\n",
        "print(scores)\r\n",
        "print(path.backtrack)\r\n",
        "print(path)\r\n",
        "print(scores[-1][-1])"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  0.  -5. -10.]\n",
            " [ -5.   4.  -1.]\n",
            " [-10.  -1.   2.]]\n",
            "[[1. 2. 2.]\n",
            " [1. 0. 2.]\n",
            " [1. 1. 0.]]\n",
            "2 2 0.0\n",
            "1 1 0.0\n",
            "AG\n",
            "AT\n",
            "2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9Cjutyts2ht",
        "outputId": "7bd9f378-053a-413d-8042-de391d2ea546"
      },
      "source": [
        "scores, path = Peptide(\"CA\").global_alignment(Peptide(\"TCA\"), read_cost_table(\"BLOSUM62\"))\r\n",
        "print(scores)\r\n",
        "print(path.backtrack)\r\n",
        "print(path)\r\n",
        "print(scores[-1][-1])"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  0.  -5. -10. -15.]\n",
            " [ -5.  -1.   4.  -1.]\n",
            " [-10.  -5.  -1.   8.]]\n",
            "[[1. 2. 2. 2.]\n",
            " [1. 0. 0. 2.]\n",
            " [1. 0. 1. 0.]]\n",
            "2 3 0.0\n",
            "1 2 0.0\n",
            "0 1 2.0\n",
            "-CA\n",
            "TCA\n",
            "8.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1fgVvdFztNUR",
        "outputId": "125c60c5-2d68-494d-db44-1aba1c2705ad"
      },
      "source": [
        "scores, path = Peptide(\"CC\").global_alignment(Peptide(\"TTTTCCTT\"), read_cost_table(\"BLOSUM62\"))\r\n",
        "print(scores)\r\n",
        "print(path.backtrack)\r\n",
        "print(path)\r\n",
        "print(scores[-1][-1])"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  0.  -5. -10. -15. -20. -25. -30. -35. -40.]\n",
            " [ -5.  -1.  -6. -11. -16. -11. -16. -21. -26.]\n",
            " [-10.  -6.  -2.  -7. -12.  -7.  -2.  -7. -12.]]\n",
            "[[1. 2. 2. 2. 2. 2. 2. 2. 2.]\n",
            " [1. 0. 2. 2. 2. 0. 2. 2. 2.]\n",
            " [1. 1. 0. 2. 2. 0. 0. 2. 2.]]\n",
            "2 8 2.0\n",
            "2 7 2.0\n",
            "2 6 0.0\n",
            "1 5 0.0\n",
            "0 4 2.0\n",
            "0 3 2.0\n",
            "0 2 2.0\n",
            "0 1 2.0\n",
            "----CC--\n",
            "TTTTCCTT\n",
            "-12.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0TnX64batSa3",
        "outputId": "f0a0c28e-251e-4f13-db9e-424bbb51f24d"
      },
      "source": [
        "scores, path = Peptide(\"T\").global_alignment(Peptide(\"ACAGATTAG\"), read_cost_table(\"BLOSUM62\"))\r\n",
        "print(scores)\r\n",
        "print(path.backtrack)\r\n",
        "print(path)\r\n",
        "print(scores[-1][-1])"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  0.  -5. -10. -15. -20. -25. -30. -35. -40. -45.]\n",
            " [ -5.   0.  -5. -10. -15. -20. -20. -25. -30. -35.]]\n",
            "[[1. 2. 2. 2. 2. 2. 2. 2. 2. 2.]\n",
            " [1. 0. 2. 2. 2. 2. 0. 2. 2. 2.]]\n",
            "1 9 2.0\n",
            "1 8 2.0\n",
            "1 7 2.0\n",
            "1 6 0.0\n",
            "0 5 2.0\n",
            "0 4 2.0\n",
            "0 3 2.0\n",
            "0 2 2.0\n",
            "0 1 2.0\n",
            "-----T---\n",
            "ACAGATTAG\n",
            "-35.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_32o8acYtyoc",
        "outputId": "a64900a9-4104-4917-ce0a-a1d1b8a94284"
      },
      "source": [
        "scores, path = Peptide(\"ACAGATTAG\").global_alignment(Peptide(\"T\"), read_cost_table(\"BLOSUM62\"))\r\n",
        "print(scores)\r\n",
        "print(path.backtrack)\r\n",
        "print(path)\r\n",
        "print(scores[-1][-1])"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  0.  -5.]\n",
            " [ -5.   0.]\n",
            " [-10.  -5.]\n",
            " [-15. -10.]\n",
            " [-20. -15.]\n",
            " [-25. -20.]\n",
            " [-30. -20.]\n",
            " [-35. -25.]\n",
            " [-40. -30.]\n",
            " [-45. -35.]]\n",
            "[[1. 2.]\n",
            " [1. 0.]\n",
            " [1. 1.]\n",
            " [1. 1.]\n",
            " [1. 1.]\n",
            " [1. 1.]\n",
            " [1. 0.]\n",
            " [1. 1.]\n",
            " [1. 1.]\n",
            " [1. 1.]]\n",
            "9 1 1.0\n",
            "8 1 1.0\n",
            "7 1 1.0\n",
            "6 1 0.0\n",
            "5 0 1.0\n",
            "4 0 1.0\n",
            "3 0 1.0\n",
            "2 0 1.0\n",
            "1 0 1.0\n",
            "ACAGATTAG\n",
            "-----T---\n",
            "-35.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJK3Y6yCtWZa",
        "outputId": "c9ae74b1-a6aa-49fb-97a8-2ac5f01f9a11"
      },
      "source": [
        "scores, path = Peptide(\"T\").global_alignment(Peptide(\"ACAGATTAG\"), read_cost_table(\"BLOSUM62\"))\r\n",
        "print(scores)\r\n",
        "print(path.backtrack)\r\n",
        "print(path)\r\n",
        "print(scores[-1][-1])"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  0.  -5. -10. -15. -20. -25. -30. -35. -40. -45.]\n",
            " [ -5.   0.  -5. -10. -15. -20. -20. -25. -30. -35.]]\n",
            "[[1. 2. 2. 2. 2. 2. 2. 2. 2. 2.]\n",
            " [1. 0. 2. 2. 2. 2. 0. 2. 2. 2.]]\n",
            "1 9 2.0\n",
            "1 8 2.0\n",
            "1 7 2.0\n",
            "1 6 0.0\n",
            "0 5 2.0\n",
            "0 4 2.0\n",
            "0 3 2.0\n",
            "0 2 2.0\n",
            "0 1 2.0\n",
            "-----T---\n",
            "ACAGATTAG\n",
            "-35.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YzFtMu9eC8PB",
        "outputId": "81dd708b-ed85-4f58-db3b-9c1b6592c449"
      },
      "source": [
        "scores, path = Peptide(\"MEANLY\").global_alignment(Peptide(\"PLEASANTLY\"), read_cost_table(\"BLOSUM62\"))\r\n",
        "print(scores)\r\n",
        "print(path.backtrack)\r\n",
        "print(path)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  0.  -5. -10. -15. -20. -25. -30. -35. -40. -45. -50.]\n",
            " [ -5.  -2.  -3.  -8. -13. -18. -23. -28. -33. -38. -43.]\n",
            " [-10.  -6.  -5.   2.  -3.  -8. -13. -18. -23. -28. -33.]\n",
            " [-15. -11.  -7.  -3.   6.   1.  -4.  -9. -14. -19. -24.]\n",
            " [-20. -16. -12.  -7.   1.   7.   2.   2.  -3.  -8. -13.]\n",
            " [-25. -21. -12. -12.  -4.   2.   6.   1.   1.   1.  -4.]\n",
            " [-30. -26. -17. -14.  -9.  -3.   1.   4.  -1.   0.   8.]]\n",
            "[[1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.]\n",
            " [1. 0. 0. 2. 2. 2. 2. 2. 2. 2. 2.]\n",
            " [1. 0. 0. 0. 2. 2. 2. 2. 2. 2. 2.]\n",
            " [1. 1. 0. 1. 0. 2. 2. 2. 2. 2. 2.]\n",
            " [1. 1. 1. 0. 1. 0. 2. 0. 2. 2. 2.]\n",
            " [1. 1. 0. 1. 1. 1. 0. 2. 0. 0. 2.]\n",
            " [1. 1. 1. 0. 1. 1. 1. 0. 2. 0. 0.]]\n",
            "6 10 0.0\n",
            "5 9 0.0\n",
            "4 8 2.0\n",
            "4 7 0.0\n",
            "3 6 2.0\n",
            "3 5 2.0\n",
            "3 4 0.0\n",
            "2 3 0.0\n",
            "1 2 0.0\n",
            "0 1 2.0\n",
            "-MEA--N-LY\n",
            "PLEASANTLY\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZeVyvPxPDFVO",
        "outputId": "1401d4b1-8c6a-41d9-8ca0-c51ec9cc94bf"
      },
      "source": [
        "scores, path = Peptide(\"ASGEEDN\").global_alignment(Peptide(\"GPPPWLSEEQN\"), read_cost_table(\"BLOSUM62\"))\r\n",
        "print(scores)\r\n",
        "print(path.backtrack)\r\n",
        "print(path)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  0.  -5. -10. -15. -20. -25. -30. -35. -40. -45. -50. -55.]\n",
            " [ -5.   0.  -5. -10. -15. -20. -25. -29. -34. -39. -44. -49.]\n",
            " [-10.  -5.  -1.  -6. -11. -16. -21. -21. -26. -31. -36. -41.]\n",
            " [-15.  -4.  -6.  -3.  -8. -13. -18. -21. -23. -28. -33. -36.]\n",
            " [-20.  -9.  -5.  -7.  -4.  -9. -14. -18. -16. -18. -23. -28.]\n",
            " [-25. -14. -10.  -6.  -8.  -7. -12. -14. -13. -11. -16. -21.]\n",
            " [-30. -19. -15. -11.  -7. -12. -11. -12. -12. -11. -11. -15.]\n",
            " [-35. -24. -20. -16. -12. -11. -15. -10. -12. -12. -11.  -5.]]\n",
            "[[1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.]\n",
            " [1. 0. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2.]\n",
            " [1. 1. 0. 2. 2. 2. 2. 0. 2. 2. 2. 2.]\n",
            " [1. 0. 1. 0. 2. 2. 2. 0. 0. 2. 2. 0.]\n",
            " [1. 1. 0. 0. 0. 2. 2. 0. 0. 0. 2. 2.]\n",
            " [1. 1. 1. 0. 0. 0. 2. 0. 0. 0. 2. 2.]\n",
            " [1. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "7 11 0.0\n",
            "6 10 0.0\n",
            "5 9 0.0\n",
            "4 8 0.0\n",
            "3 7 0.0\n",
            "2 6 2.0\n",
            "2 5 2.0\n",
            "2 4 2.0\n",
            "2 3 2.0\n",
            "2 2 0.0\n",
            "1 1 0.0\n",
            "AS----GEEDN\n",
            "GPPPWLSEEQN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4ZyDwD-KIh8",
        "outputId": "2b3eb225-a155-4804-c31f-0153d7bfd2d2"
      },
      "source": [
        "scores, path = Peptide(\"GAGA\").global_alignment(Peptide(\"GAT\"), read_cost_table(\"BLOSUM62\"), 1)\r\n",
        "print(scores)\r\n",
        "print(path.backtrack)\r\n",
        "print(path)\r\n"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0. -1. -2. -3.]\n",
            " [-1.  6.  5.  4.]\n",
            " [-2.  5. 10.  9.]\n",
            " [-3.  4.  9.  8.]\n",
            " [-4.  3.  8.  9.]]\n",
            "[[1. 2. 2. 2.]\n",
            " [1. 0. 2. 2.]\n",
            " [1. 1. 0. 2.]\n",
            " [1. 1. 1. 1.]\n",
            " [1. 1. 1. 0.]]\n",
            "4 3 0.0\n",
            "3 2 1.0\n",
            "2 2 0.0\n",
            "1 1 0.0\n",
            "GAGA\n",
            "GA-T\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZR154LtLA-B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d498458-11d4-4f50-e76f-c42e9490d30e"
      },
      "source": [
        "scores, path = Peptide(\"GAT\").global_alignment(Peptide(\"GAGA\"), read_cost_table(\"BLOSUM62\"), 1)\r\n",
        "print(scores)\r\n",
        "print(path.backtrack)\r\n",
        "print(path)\r\n"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0. -1. -2. -3. -4.]\n",
            " [-1.  6.  5.  4.  3.]\n",
            " [-2.  5. 10.  9.  8.]\n",
            " [-3.  4.  9.  8.  9.]]\n",
            "[[1. 2. 2. 2. 2.]\n",
            " [1. 0. 2. 2. 2.]\n",
            " [1. 1. 0. 2. 2.]\n",
            " [1. 1. 1. 1. 0.]]\n",
            "3 4 0.0\n",
            "2 3 2.0\n",
            "2 2 0.0\n",
            "1 1 0.0\n",
            "GA-T\n",
            "GAGA\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpdmkmVCqzFJ",
        "outputId": "3152c3e2-a768-4dde-bab9-94f9b2d92283"
      },
      "source": [
        "scores, path = Peptide(\"ILIPRQQMGCFPFPWHFDFCFWSAHHSLVVPLNPQMQTVFQNRGLDRVTVKTDCHDHRWKWIYNLGLPTMTAGDWHFIKKHVVRANNPHQWFQGRLTTAWLHSTFLYKKTEYCLVRHSNCCHCDWDQIIHTCAFIAFLDLYQRHWPMCDKLYCHFHHSWFCRNQEMSMDWNQWFPWDSVPRANCLEEGALIALYAGIWANSMKRDMKTDHACTVRLIYVCELHAWLKYCYTSINMLCGNVCLRCKSWIFVKLFYMYAPVVNTIEANSPHYYKRCCILGQGICPVERKSHCEIYAKDLLSFESCCSQKQNCYTDNWGLEYRLFFQHIQMECTDPHANRGWTSCQTAKYWHFNLDDRPPKEFYMWLQATPTDLCMYQHCLMFKIVKQNFRKQHGHANPAASTSGNWDSVYTPEKMAYKDWYVSHPPVDMRRNGSKMVPVWYPPGIWHWKQSYKLTYECFFTVPGRFHVEGTFGCNRWDHQPGTRRDRQANHQFQCPYSDTMAIWEHAYTYVDQWRSIKEGQMPMSGYPNHGQWNVHDDHTNEQERSPICNQPVLAKFVRSKNVSNHEICKKSQTVFHWACEAQTNVCERMLNNQHVAVKRNVTFWWQMVPNCLWSCHNKMTWPTRPEQHRLFFVKMRLKCMHEYLDVAPSDFCRNMQAYMHSMRAILEYQADFDLKRRLRAIAPMDLCAQYDQEIILWSGGYIYDQSLQVVSCEGCSYYADCYVKCINVKEKCMFA\").global_alignment(Peptide(\"ILYPRQSMICMSFCFWDMWKKDVPVVLMMFLERRQMQSVFSWLVTVKTDCGKGIYNHRKYLGLPTMTAGDWHWIKKQNDPHEWFQGRLETAWLHSTFLYWKYFECDAVKVCMDTFGLFGHCDWDQQIHTCTHENEPAIAFLDLYCRHSPMCDKLYPVWDMACQTCHFHHSWFCRNQEMWMKGDVDDWQWGYHYHTINSAQCNQWFKEICKDMGWDSVFPPRHNCQRHKKCMPALYAGIWMATDHACTFMVRLIYTENIAEWHQVYCYRSMNMFTCGNVCLRCKSWIFVKNYMMAPVVNDPMIEAFYKRCCILGKAWYDMWGICPVERKSHWEIYAKDLLSFESCCSQKKQNCYTDNWGLEYRLFFQSIQMNTDPHYCQTHVCWISAMFPIYSPFYTSGPKEFYMWLQARIDQNMHGHANHYVTSGNWDSVYTPEKRAGVFPVVVPVWYPPQMCNDYIKLTYECERFHVEGTFGCNRWDLGCRRYIIFQCPYCDTMKICYVDQWRSIKEGQFRMSGYPNHGYWFVHDDHTNEWCNQPVLAKFVRSKIVAICKKSQTVFHYAYTPGYNATWPQTNVCERMYGPHDNLLNNQQNVTFWWKMVPNCGMQILISCHNKMKWPTSHYVFMRLKCMHVLMQMEYLDHFTGPGEGDFCRNMQPYMHQDLHWEGSMRAILEYQAEHHRRAFRAELCAQYDQEIILWSGGWGVQDCGFHANYDGSLQVVSGEPCSMWCTTVMQYYADCWEKCMFA\"), read_cost_table(\"BLOSUM62\"))\r\n",
        "print(scores)\r\n",
        "print(path.backtrack)\r\n",
        "print(path)\r\n",
        "print(scores[-1][-1])"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0.000e+00 -5.000e+00 -1.000e+01 ... -3.715e+03 -3.720e+03 -3.725e+03]\n",
            " [-5.000e+00  4.000e+00 -1.000e+00 ... -3.706e+03 -3.711e+03 -3.716e+03]\n",
            " [-1.000e+01 -1.000e+00  8.000e+00 ... -3.697e+03 -3.702e+03 -3.707e+03]\n",
            " ...\n",
            " [-3.660e+03 -3.651e+03 -3.642e+03 ...  1.545e+03  1.540e+03  1.535e+03]\n",
            " [-3.665e+03 -3.656e+03 -3.647e+03 ...  1.540e+03  1.551e+03  1.546e+03]\n",
            " [-3.670e+03 -3.661e+03 -3.652e+03 ...  1.535e+03  1.546e+03  1.555e+03]]\n",
            "[[1. 2. 2. ... 2. 2. 2.]\n",
            " [1. 0. 2. ... 2. 2. 2.]\n",
            " [1. 1. 0. ... 2. 2. 2.]\n",
            " ...\n",
            " [1. 1. 1. ... 0. 2. 2.]\n",
            " [1. 1. 1. ... 1. 0. 2.]\n",
            " [1. 1. 1. ... 1. 1. 0.]]\n",
            "734 745 0.0\n",
            "733 744 0.0\n",
            "732 743 0.0\n",
            "731 742 0.0\n",
            "730 741 0.0\n",
            "729 740 0.0\n",
            "728 739 0.0\n",
            "727 738 0.0\n",
            "726 737 0.0\n",
            "725 736 2.0\n",
            "725 735 0.0\n",
            "724 734 0.0\n",
            "723 733 0.0\n",
            "722 732 0.0\n",
            "721 731 0.0\n",
            "720 730 0.0\n",
            "719 729 0.0\n",
            "718 728 0.0\n",
            "717 727 0.0\n",
            "716 726 0.0\n",
            "715 725 0.0\n",
            "714 724 0.0\n",
            "713 723 0.0\n",
            "712 722 0.0\n",
            "711 721 0.0\n",
            "710 720 0.0\n",
            "709 719 0.0\n",
            "708 718 0.0\n",
            "707 717 0.0\n",
            "706 716 0.0\n",
            "705 715 0.0\n",
            "704 714 0.0\n",
            "703 713 0.0\n",
            "702 712 0.0\n",
            "701 711 2.0\n",
            "701 710 2.0\n",
            "701 709 2.0\n",
            "701 708 2.0\n",
            "701 707 2.0\n",
            "701 706 2.0\n",
            "701 705 2.0\n",
            "701 704 2.0\n",
            "701 703 0.0\n",
            "700 702 2.0\n",
            "700 701 0.0\n",
            "699 700 0.0\n",
            "698 699 0.0\n",
            "697 698 0.0\n",
            "696 697 0.0\n",
            "695 696 0.0\n",
            "694 695 0.0\n",
            "693 694 0.0\n",
            "692 693 0.0\n",
            "691 692 0.0\n",
            "690 691 0.0\n",
            "689 690 0.0\n",
            "688 689 0.0\n",
            "687 688 0.0\n",
            "686 687 0.0\n",
            "685 686 0.0\n",
            "684 685 0.0\n",
            "683 684 1.0\n",
            "682 684 1.0\n",
            "681 684 1.0\n",
            "680 684 1.0\n",
            "679 684 0.0\n",
            "678 683 0.0\n",
            "677 682 0.0\n",
            "676 681 0.0\n",
            "675 680 0.0\n",
            "674 679 0.0\n",
            "673 678 1.0\n",
            "672 678 0.0\n",
            "671 677 0.0\n",
            "670 676 0.0\n",
            "669 675 0.0\n",
            "668 674 0.0\n",
            "667 673 0.0\n",
            "666 672 0.0\n",
            "665 671 0.0\n",
            "664 670 0.0\n",
            "663 669 0.0\n",
            "662 668 0.0\n",
            "661 667 0.0\n",
            "660 666 0.0\n",
            "659 665 2.0\n",
            "659 664 2.0\n",
            "659 663 2.0\n",
            "659 662 2.0\n",
            "659 661 2.0\n",
            "659 660 2.0\n",
            "659 659 2.0\n",
            "659 658 0.0\n",
            "658 657 0.0\n",
            "657 656 0.0\n",
            "656 655 0.0\n",
            "655 654 0.0\n",
            "654 653 0.0\n",
            "653 652 0.0\n",
            "652 651 0.0\n",
            "651 650 0.0\n",
            "650 649 0.0\n",
            "649 648 0.0\n",
            "648 647 2.0\n",
            "648 646 2.0\n",
            "648 645 0.0\n",
            "647 644 0.0\n",
            "646 643 0.0\n",
            "645 642 0.0\n",
            "644 641 2.0\n",
            "644 640 2.0\n",
            "644 639 0.0\n",
            "643 638 0.0\n",
            "642 637 0.0\n",
            "641 636 0.0\n",
            "640 635 2.0\n",
            "640 634 2.0\n",
            "640 633 2.0\n",
            "640 632 2.0\n",
            "640 631 2.0\n",
            "640 630 0.0\n",
            "639 629 0.0\n",
            "638 628 0.0\n",
            "637 627 0.0\n",
            "636 626 0.0\n",
            "635 625 0.0\n",
            "634 624 0.0\n",
            "633 623 1.0\n",
            "632 623 1.0\n",
            "631 623 1.0\n",
            "630 623 0.0\n",
            "629 622 0.0\n",
            "628 621 0.0\n",
            "627 620 0.0\n",
            "626 619 1.0\n",
            "625 619 0.0\n",
            "624 618 1.0\n",
            "623 618 1.0\n",
            "622 618 0.0\n",
            "621 617 0.0\n",
            "620 616 0.0\n",
            "619 615 0.0\n",
            "618 614 0.0\n",
            "617 613 0.0\n",
            "616 612 0.0\n",
            "615 611 0.0\n",
            "614 610 0.0\n",
            "613 609 0.0\n",
            "612 608 0.0\n",
            "611 607 0.0\n",
            "610 606 2.0\n",
            "610 605 2.0\n",
            "610 604 2.0\n",
            "610 603 2.0\n",
            "610 602 0.0\n",
            "609 601 0.0\n",
            "608 600 0.0\n",
            "607 599 0.0\n",
            "606 598 0.0\n",
            "605 597 0.0\n",
            "604 596 0.0\n",
            "603 595 0.0\n",
            "602 594 0.0\n",
            "601 593 0.0\n",
            "600 592 0.0\n",
            "599 591 0.0\n",
            "598 590 0.0\n",
            "597 589 0.0\n",
            "596 588 2.0\n",
            "596 587 0.0\n",
            "595 586 0.0\n",
            "594 585 0.0\n",
            "593 584 0.0\n",
            "592 583 0.0\n",
            "591 582 0.0\n",
            "590 581 2.0\n",
            "590 580 0.0\n",
            "589 579 0.0\n",
            "588 578 0.0\n",
            "587 577 0.0\n",
            "586 576 0.0\n",
            "585 575 0.0\n",
            "584 574 0.0\n",
            "583 573 0.0\n",
            "582 572 0.0\n",
            "581 571 0.0\n",
            "580 570 2.0\n",
            "580 569 2.0\n",
            "580 568 2.0\n",
            "580 567 0.0\n",
            "579 566 0.0\n",
            "578 565 2.0\n",
            "578 564 2.0\n",
            "578 563 2.0\n",
            "578 562 0.0\n",
            "577 561 2.0\n",
            "577 560 0.0\n",
            "576 559 0.0\n",
            "575 558 0.0\n",
            "574 557 0.0\n",
            "573 556 0.0\n",
            "572 555 0.0\n",
            "571 554 0.0\n",
            "570 553 0.0\n",
            "569 552 0.0\n",
            "568 551 0.0\n",
            "567 550 0.0\n",
            "566 549 0.0\n",
            "565 548 1.0\n",
            "564 548 1.0\n",
            "563 548 1.0\n",
            "562 548 0.0\n",
            "561 547 0.0\n",
            "560 546 0.0\n",
            "559 545 0.0\n",
            "558 544 0.0\n",
            "557 543 0.0\n",
            "556 542 0.0\n",
            "555 541 0.0\n",
            "554 540 0.0\n",
            "553 539 0.0\n",
            "552 538 0.0\n",
            "551 537 0.0\n",
            "550 536 0.0\n",
            "549 535 0.0\n",
            "548 534 0.0\n",
            "547 533 0.0\n",
            "546 532 1.0\n",
            "545 532 1.0\n",
            "544 532 1.0\n",
            "543 532 1.0\n",
            "542 532 1.0\n",
            "541 532 0.0\n",
            "540 531 0.0\n",
            "539 530 0.0\n",
            "538 529 0.0\n",
            "537 528 0.0\n",
            "536 527 0.0\n",
            "535 526 0.0\n",
            "534 525 0.0\n",
            "533 524 0.0\n",
            "532 523 0.0\n",
            "531 522 0.0\n",
            "530 521 0.0\n",
            "529 520 0.0\n",
            "528 519 0.0\n",
            "527 518 0.0\n",
            "526 517 0.0\n",
            "525 516 0.0\n",
            "524 515 0.0\n",
            "523 514 0.0\n",
            "522 513 0.0\n",
            "521 512 0.0\n",
            "520 511 0.0\n",
            "519 510 0.0\n",
            "518 509 0.0\n",
            "517 508 0.0\n",
            "516 507 0.0\n",
            "515 506 0.0\n",
            "514 505 0.0\n",
            "513 504 0.0\n",
            "512 503 0.0\n",
            "511 502 0.0\n",
            "510 501 0.0\n",
            "509 500 0.0\n",
            "508 499 1.0\n",
            "507 499 1.0\n",
            "506 499 0.0\n",
            "505 498 0.0\n",
            "504 497 1.0\n",
            "503 497 1.0\n",
            "502 497 1.0\n",
            "501 497 0.0\n",
            "500 496 0.0\n",
            "499 495 0.0\n",
            "498 494 0.0\n",
            "497 493 0.0\n",
            "496 492 0.0\n",
            "495 491 0.0\n",
            "494 490 0.0\n",
            "493 489 0.0\n",
            "492 488 0.0\n",
            "491 487 0.0\n",
            "490 486 1.0\n",
            "489 486 1.0\n",
            "488 486 0.0\n",
            "487 485 0.0\n",
            "486 484 0.0\n",
            "485 483 1.0\n",
            "484 483 1.0\n",
            "483 483 0.0\n",
            "482 482 0.0\n",
            "481 481 0.0\n",
            "480 480 0.0\n",
            "479 479 1.0\n",
            "478 479 0.0\n",
            "477 478 1.0\n",
            "476 478 0.0\n",
            "475 477 0.0\n",
            "474 476 0.0\n",
            "473 475 0.0\n",
            "472 474 0.0\n",
            "471 473 0.0\n",
            "470 472 0.0\n",
            "469 471 0.0\n",
            "468 470 0.0\n",
            "467 469 0.0\n",
            "466 468 0.0\n",
            "465 467 0.0\n",
            "464 466 0.0\n",
            "463 465 0.0\n",
            "462 464 1.0\n",
            "461 464 1.0\n",
            "460 464 1.0\n",
            "459 464 0.0\n",
            "458 463 1.0\n",
            "457 463 1.0\n",
            "456 463 0.0\n",
            "455 462 0.0\n",
            "454 461 0.0\n",
            "453 460 0.0\n",
            "452 459 0.0\n",
            "451 458 0.0\n",
            "450 457 2.0\n",
            "450 456 0.0\n",
            "449 455 1.0\n",
            "448 455 0.0\n",
            "447 454 1.0\n",
            "446 454 1.0\n",
            "445 454 0.0\n",
            "444 453 0.0\n",
            "443 452 0.0\n",
            "442 451 0.0\n",
            "441 450 0.0\n",
            "440 449 0.0\n",
            "439 448 0.0\n",
            "438 447 0.0\n",
            "437 446 0.0\n",
            "436 445 0.0\n",
            "435 444 0.0\n",
            "434 443 1.0\n",
            "433 443 1.0\n",
            "432 443 1.0\n",
            "431 443 1.0\n",
            "430 443 1.0\n",
            "429 443 1.0\n",
            "428 443 1.0\n",
            "427 443 0.0\n",
            "426 442 1.0\n",
            "425 442 0.0\n",
            "424 441 1.0\n",
            "423 441 0.0\n",
            "422 440 0.0\n",
            "421 439 1.0\n",
            "420 439 0.0\n",
            "419 438 1.0\n",
            "418 438 1.0\n",
            "417 438 0.0\n",
            "416 437 1.0\n",
            "415 437 1.0\n",
            "414 437 0.0\n",
            "413 436 0.0\n",
            "412 435 0.0\n",
            "411 434 0.0\n",
            "410 433 0.0\n",
            "409 432 0.0\n",
            "408 431 0.0\n",
            "407 430 0.0\n",
            "406 429 0.0\n",
            "405 428 0.0\n",
            "404 427 0.0\n",
            "403 426 0.0\n",
            "402 425 0.0\n",
            "401 424 0.0\n",
            "400 423 0.0\n",
            "399 422 1.0\n",
            "398 422 0.0\n",
            "397 421 0.0\n",
            "396 420 0.0\n",
            "395 419 0.0\n",
            "394 418 0.0\n",
            "393 417 0.0\n",
            "392 416 0.0\n",
            "391 415 0.0\n",
            "390 414 1.0\n",
            "389 414 1.0\n",
            "388 414 1.0\n",
            "387 414 0.0\n",
            "386 413 0.0\n",
            "385 412 0.0\n",
            "384 411 0.0\n",
            "383 410 1.0\n",
            "382 410 0.0\n",
            "381 409 0.0\n",
            "380 408 0.0\n",
            "379 407 0.0\n",
            "378 406 0.0\n",
            "377 405 1.0\n",
            "376 405 1.0\n",
            "375 405 1.0\n",
            "374 405 0.0\n",
            "373 404 0.0\n",
            "372 403 0.0\n",
            "371 402 0.0\n",
            "370 401 0.0\n",
            "369 400 0.0\n",
            "368 399 0.0\n",
            "367 398 1.0\n",
            "366 398 0.0\n",
            "365 397 0.0\n",
            "364 396 1.0\n",
            "363 396 1.0\n",
            "362 396 0.0\n",
            "361 395 0.0\n",
            "360 394 0.0\n",
            "359 393 0.0\n",
            "358 392 0.0\n",
            "357 391 2.0\n",
            "357 390 0.0\n",
            "356 389 0.0\n",
            "355 388 1.0\n",
            "354 388 0.0\n",
            "353 387 0.0\n",
            "352 386 0.0\n",
            "351 385 0.0\n",
            "350 384 0.0\n",
            "349 383 1.0\n",
            "348 383 0.0\n",
            "347 382 0.0\n",
            "346 381 0.0\n",
            "345 380 0.0\n",
            "344 379 0.0\n",
            "343 378 0.0\n",
            "342 377 0.0\n",
            "341 376 1.0\n",
            "340 376 1.0\n",
            "339 376 0.0\n",
            "338 375 1.0\n",
            "337 375 1.0\n",
            "336 375 1.0\n",
            "335 375 1.0\n",
            "334 375 0.0\n",
            "333 374 0.0\n",
            "332 373 0.0\n",
            "331 372 0.0\n",
            "330 371 1.0\n",
            "329 371 0.0\n",
            "328 370 0.0\n",
            "327 369 0.0\n",
            "326 368 0.0\n",
            "325 367 0.0\n",
            "324 366 0.0\n",
            "323 365 0.0\n",
            "322 364 0.0\n",
            "321 363 0.0\n",
            "320 362 0.0\n",
            "319 361 0.0\n",
            "318 360 0.0\n",
            "317 359 0.0\n",
            "316 358 0.0\n",
            "315 357 0.0\n",
            "314 356 0.0\n",
            "313 355 0.0\n",
            "312 354 0.0\n",
            "311 353 0.0\n",
            "310 352 0.0\n",
            "309 351 0.0\n",
            "308 350 0.0\n",
            "307 349 2.0\n",
            "307 348 0.0\n",
            "306 347 0.0\n",
            "305 346 0.0\n",
            "304 345 0.0\n",
            "303 344 0.0\n",
            "302 343 0.0\n",
            "301 342 0.0\n",
            "300 341 0.0\n",
            "299 340 0.0\n",
            "298 339 0.0\n",
            "297 338 0.0\n",
            "296 337 0.0\n",
            "295 336 0.0\n",
            "294 335 0.0\n",
            "293 334 0.0\n",
            "292 333 0.0\n",
            "291 332 0.0\n",
            "290 331 0.0\n",
            "289 330 0.0\n",
            "288 329 0.0\n",
            "287 328 0.0\n",
            "286 327 0.0\n",
            "285 326 0.0\n",
            "284 325 0.0\n",
            "283 324 0.0\n",
            "282 323 0.0\n",
            "281 322 0.0\n",
            "280 321 0.0\n",
            "279 320 2.0\n",
            "279 319 2.0\n",
            "279 318 2.0\n",
            "279 317 2.0\n",
            "279 316 2.0\n",
            "279 315 2.0\n",
            "279 314 0.0\n",
            "278 313 0.0\n",
            "277 312 0.0\n",
            "276 311 0.0\n",
            "275 310 0.0\n",
            "274 309 0.0\n",
            "273 308 0.0\n",
            "272 307 0.0\n",
            "271 306 0.0\n",
            "270 305 0.0\n",
            "269 304 1.0\n",
            "268 304 1.0\n",
            "267 304 0.0\n",
            "266 303 0.0\n",
            "265 302 0.0\n",
            "264 301 0.0\n",
            "263 300 0.0\n",
            "262 299 0.0\n",
            "261 298 0.0\n",
            "260 297 0.0\n",
            "259 296 0.0\n",
            "258 295 0.0\n",
            "257 294 0.0\n",
            "256 293 0.0\n",
            "255 292 0.0\n",
            "254 291 0.0\n",
            "253 290 1.0\n",
            "252 290 0.0\n",
            "251 289 0.0\n",
            "250 288 0.0\n",
            "249 287 0.0\n",
            "248 286 0.0\n",
            "247 285 0.0\n",
            "246 284 0.0\n",
            "245 283 0.0\n",
            "244 282 0.0\n",
            "243 281 0.0\n",
            "242 280 0.0\n",
            "241 279 0.0\n",
            "240 278 0.0\n",
            "239 277 0.0\n",
            "238 276 0.0\n",
            "237 275 0.0\n",
            "236 274 2.0\n",
            "236 273 0.0\n",
            "235 272 0.0\n",
            "234 271 0.0\n",
            "233 270 0.0\n",
            "232 269 0.0\n",
            "231 268 0.0\n",
            "230 267 0.0\n",
            "229 266 0.0\n",
            "228 265 0.0\n",
            "227 264 2.0\n",
            "227 263 0.0\n",
            "226 262 0.0\n",
            "225 261 0.0\n",
            "224 260 0.0\n",
            "223 259 0.0\n",
            "222 258 0.0\n",
            "221 257 0.0\n",
            "220 256 0.0\n",
            "219 255 0.0\n",
            "218 254 0.0\n",
            "217 253 0.0\n",
            "216 252 0.0\n",
            "215 251 0.0\n",
            "214 250 0.0\n",
            "213 249 2.0\n",
            "213 248 2.0\n",
            "213 247 0.0\n",
            "212 246 0.0\n",
            "211 245 0.0\n",
            "210 244 0.0\n",
            "209 243 0.0\n",
            "208 242 0.0\n",
            "207 241 1.0\n",
            "206 241 1.0\n",
            "205 241 1.0\n",
            "204 241 1.0\n",
            "203 241 0.0\n",
            "202 240 0.0\n",
            "201 239 1.0\n",
            "200 239 1.0\n",
            "199 239 1.0\n",
            "198 239 0.0\n",
            "197 238 0.0\n",
            "196 237 0.0\n",
            "195 236 0.0\n",
            "194 235 0.0\n",
            "193 234 0.0\n",
            "192 233 0.0\n",
            "191 232 0.0\n",
            "190 231 0.0\n",
            "189 230 0.0\n",
            "188 229 0.0\n",
            "187 228 0.0\n",
            "186 227 2.0\n",
            "186 226 0.0\n",
            "185 225 0.0\n",
            "184 224 0.0\n",
            "183 223 0.0\n",
            "182 222 0.0\n",
            "181 221 0.0\n",
            "180 220 2.0\n",
            "180 219 0.0\n",
            "179 218 2.0\n",
            "179 217 0.0\n",
            "178 216 0.0\n",
            "177 215 0.0\n",
            "176 214 0.0\n",
            "175 213 2.0\n",
            "175 212 2.0\n",
            "175 211 2.0\n",
            "175 210 2.0\n",
            "175 209 2.0\n",
            "175 208 2.0\n",
            "175 207 2.0\n",
            "175 206 0.0\n",
            "174 205 0.0\n",
            "173 204 0.0\n",
            "172 203 2.0\n",
            "172 202 2.0\n",
            "172 201 2.0\n",
            "172 200 0.0\n",
            "171 199 2.0\n",
            "171 198 2.0\n",
            "171 197 0.0\n",
            "170 196 2.0\n",
            "170 195 2.0\n",
            "170 194 2.0\n",
            "170 193 2.0\n",
            "170 192 2.0\n",
            "170 191 2.0\n",
            "170 190 2.0\n",
            "170 189 2.0\n",
            "170 188 2.0\n",
            "170 187 0.0\n",
            "169 186 2.0\n",
            "169 185 2.0\n",
            "169 184 2.0\n",
            "169 183 0.0\n",
            "168 182 2.0\n",
            "168 181 2.0\n",
            "168 180 0.0\n",
            "167 179 0.0\n",
            "166 178 0.0\n",
            "165 177 0.0\n",
            "164 176 0.0\n",
            "163 175 0.0\n",
            "162 174 0.0\n",
            "161 173 0.0\n",
            "160 172 0.0\n",
            "159 171 0.0\n",
            "158 170 0.0\n",
            "157 169 0.0\n",
            "156 168 0.0\n",
            "155 167 0.0\n",
            "154 166 0.0\n",
            "153 165 2.0\n",
            "153 164 2.0\n",
            "153 163 2.0\n",
            "153 162 0.0\n",
            "152 161 2.0\n",
            "152 160 2.0\n",
            "152 159 2.0\n",
            "152 158 2.0\n",
            "152 157 2.0\n",
            "152 156 2.0\n",
            "152 155 0.0\n",
            "151 154 0.0\n",
            "150 153 0.0\n",
            "149 152 0.0\n",
            "148 151 0.0\n",
            "147 150 0.0\n",
            "146 149 0.0\n",
            "145 148 0.0\n",
            "144 147 0.0\n",
            "143 146 0.0\n",
            "142 145 0.0\n",
            "141 144 0.0\n",
            "140 143 0.0\n",
            "139 142 0.0\n",
            "138 141 0.0\n",
            "137 140 0.0\n",
            "136 139 0.0\n",
            "135 138 0.0\n",
            "134 137 2.0\n",
            "134 136 2.0\n",
            "134 135 2.0\n",
            "134 134 2.0\n",
            "134 133 2.0\n",
            "134 132 0.0\n",
            "133 131 0.0\n",
            "132 130 0.0\n",
            "131 129 0.0\n",
            "130 128 0.0\n",
            "129 127 0.0\n",
            "128 126 0.0\n",
            "127 125 0.0\n",
            "126 124 0.0\n",
            "125 123 0.0\n",
            "124 122 0.0\n",
            "123 121 0.0\n",
            "122 120 0.0\n",
            "121 119 2.0\n",
            "121 118 0.0\n",
            "120 117 0.0\n",
            "119 116 0.0\n",
            "118 115 2.0\n",
            "118 114 0.0\n",
            "117 113 0.0\n",
            "116 112 2.0\n",
            "116 111 2.0\n",
            "116 110 2.0\n",
            "116 109 0.0\n",
            "115 108 0.0\n",
            "114 107 0.0\n",
            "113 106 2.0\n",
            "113 105 0.0\n",
            "112 104 1.0\n",
            "111 104 0.0\n",
            "110 103 0.0\n",
            "109 102 0.0\n",
            "108 101 0.0\n",
            "107 100 2.0\n",
            "107 99 0.0\n",
            "106 98 0.0\n",
            "105 97 0.0\n",
            "104 96 0.0\n",
            "103 95 0.0\n",
            "102 94 0.0\n",
            "101 93 0.0\n",
            "100 92 0.0\n",
            "99 91 0.0\n",
            "98 90 0.0\n",
            "97 89 0.0\n",
            "96 88 0.0\n",
            "95 87 0.0\n",
            "94 86 0.0\n",
            "93 85 0.0\n",
            "92 84 0.0\n",
            "91 83 0.0\n",
            "90 82 0.0\n",
            "89 81 0.0\n",
            "88 80 0.0\n",
            "87 79 0.0\n",
            "86 78 0.0\n",
            "85 77 1.0\n",
            "84 77 0.0\n",
            "83 76 1.0\n",
            "82 76 1.0\n",
            "81 76 1.0\n",
            "80 76 0.0\n",
            "79 75 0.0\n",
            "78 74 0.0\n",
            "77 73 0.0\n",
            "76 72 0.0\n",
            "75 71 0.0\n",
            "74 70 0.0\n",
            "73 69 0.0\n",
            "72 68 0.0\n",
            "71 67 0.0\n",
            "70 66 0.0\n",
            "69 65 0.0\n",
            "68 64 0.0\n",
            "67 63 0.0\n",
            "66 62 0.0\n",
            "65 61 0.0\n",
            "64 60 1.0\n",
            "63 60 0.0\n",
            "62 59 1.0\n",
            "61 59 1.0\n",
            "60 59 0.0\n",
            "59 58 1.0\n",
            "58 58 0.0\n",
            "57 57 0.0\n",
            "56 56 0.0\n",
            "55 55 0.0\n",
            "54 54 2.0\n",
            "54 53 2.0\n",
            "54 52 2.0\n",
            "54 51 2.0\n",
            "54 50 0.0\n",
            "53 49 0.0\n",
            "52 48 0.0\n",
            "51 47 0.0\n",
            "50 46 0.0\n",
            "49 45 0.0\n",
            "48 44 0.0\n",
            "47 43 1.0\n",
            "46 43 1.0\n",
            "45 43 0.0\n",
            "44 42 0.0\n",
            "43 41 1.0\n",
            "42 41 0.0\n",
            "41 40 1.0\n",
            "40 40 0.0\n",
            "39 39 0.0\n",
            "38 38 0.0\n",
            "37 37 0.0\n",
            "36 36 0.0\n",
            "35 35 0.0\n",
            "34 34 2.0\n",
            "34 33 0.0\n",
            "33 32 0.0\n",
            "32 31 0.0\n",
            "31 30 2.0\n",
            "31 29 2.0\n",
            "31 28 0.0\n",
            "30 27 0.0\n",
            "29 26 0.0\n",
            "28 25 0.0\n",
            "27 24 0.0\n",
            "26 23 0.0\n",
            "25 22 0.0\n",
            "24 21 0.0\n",
            "23 20 0.0\n",
            "22 19 0.0\n",
            "21 18 1.0\n",
            "20 18 1.0\n",
            "19 18 0.0\n",
            "18 17 0.0\n",
            "17 16 0.0\n",
            "16 15 1.0\n",
            "15 15 0.0\n",
            "14 14 0.0\n",
            "13 13 0.0\n",
            "12 12 0.0\n",
            "11 11 0.0\n",
            "10 10 0.0\n",
            "9 9 0.0\n",
            "8 8 0.0\n",
            "7 7 0.0\n",
            "6 6 0.0\n",
            "5 5 0.0\n",
            "4 4 0.0\n",
            "3 3 0.0\n",
            "2 2 0.0\n",
            "1 1 0.0\n",
            "ILIPRQQMGCFPFPWHFDFCFWSAHHSLVVP--LNP-QMQTVFQNRGLDRVTVKTDC----HDHRWKWIYNLGLPTMTAGDWHFIKKHVVRANNPHQWFQGRLTTAWLHSTFLY-KKTEYC-LVR---HS-NCC-HCDWDQIIHTCAF-----IAFLDLYQRHWPMCDKLY------C---HFHHSWFCRNQEMSM--D---W---------N--Q---WFP-------WDSV-P-RANCLE-EGALIALYAGIWANSMKRDMKTDHACT--VRLIYVCELHAWLK-YCYTSINML-CGNVCLRCKSWIFVKLFYMYAPVVNTIEANSPHYYKRCCILGQ------GICPVERKSHCEIYAKDLLSFESCCSQK-QNCYTDNWGLEYRLFFQHIQMECTDPHANRGWTSCQTAKYWHFNLDDRPP-KEFYMWLQATPTDLCMYQHCLMFKIVKQNFRKQHGHANPAASTSGNWDSVYTPEKMAYKDWYVSHPPVDMRRNGSKMVPVWYPPGIWHWKQSY-KLTYECFFTVPGRFHVEGTFGCNRWDHQPGTRRDRQANHQFQCPYSDTMAIWEHAYTYVDQWRSIKEGQMPMSGYPNHGQWNVHDDHTNEQERSPICNQPVLAKFVRSKNVSNHEICKKSQTVFHWA-C---EA---QTNVCERMLN-NQHVAV-KRNVTFWWQMVPNC----LWSCHNKMTWPTRPEQHRLFFVKMRLKCMH-----EYLD--VAPS--DFCRNMQAYMH-------SMRAILEYQADFDLKRRLRAIAPMDLCAQYDQEIILWSGGY-I--------YDQSLQVVSCEGCSYYADCYVKCI-NVKEKCMFA\n",
            "ILYPRQSMICMSFCF-WDM--WKKDVPVVLMMFLERRQMQSVF-S-WL--VTVKTDCGKGIYNHR-K--Y-LGLPTMTAGDWHWIKK---Q-NDPHEWFQGRLETAWLHSTFLYWKYFE-CDAVKVCMDTFGLFGHCDWDQQIHTCTHENEPAIAFLDLYCRHSPMCDKLYPVWDMACQTCHFHHSWFCRNQEMWMKGDVDDWQWGYHYHTINSAQCNQWFKEICKDMGWDSVFPPRHNCQRHKKCMPALYAGIW---MA----TDHACTFMVRLIYTENIAEWHQVYCYRSMNMFTCGNVCLRCKSWIFVKN-YMMAPVVNDPMIEA--FYKRCCILGKAWYDMWGICPVERKSHWEIYAKDLLSFESCCSQKKQNCYTDNWGLEYRLFFQSIQMN-TDPH----Y--CQTHVCW-ISAMF-PIYSPFYT--SG-PKEFYMW---LQARI-DQNM---HGHANHYV-TSGNWDSVYTPEKRA--G--V-FP-V-V-------VPVWYPPQMCN--D-YIKLTYEC--E---RFHVEGTFGCNRWD-L-GCRR--YII--FQCPYCDTMKI---CY--VDQWRSIKEGQFRMSGYPNHGYWFVHDDHTNEW-----CNQPVLAKFVRSKIVA---ICKKSQTVFHYAYTPGYNATWPQTNVCERMYGPHDNLLNNQQNVTFWWKMVPNCGMQILISCHNKMKWPT--S-HYVF---MRLKCMHVLMQMEYLDHFTGPGEGDFCRNMQPYMHQDLHWEGSMRAILEYQAEHH-RRAFRA----ELCAQYDQEIILWSGGWGVQDCGFHANYDGSLQVVSGEPCSMWCTTVMQYYADCWEKCMFA\n",
            "1555.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qakocCE4rNAQ",
        "outputId": "dad87d5f-b739-4353-de6d-d47bc6c82a92"
      },
      "source": [
        "scores, path = Peptide(\"RAYRFVVANGFRNATIWCKPFYTRFKHSHMGYHATYNVKCWGDTPFGMAHSILGCCNMYYSFRCKWHWCIDTMAPSKVQLARILSHTTSYWHLCSGNDRWYDCCIRKWEIDQVHGHTLMMFFYMRLQCSDRHDLCIMWWSNDNNNWGVVIYNIKHRILLKAVPRQWDYMCVVYRSCHWLLPKRYDPAYLIFCWDNVQQCFEHPATEQECDICADDVYSRDVICKDPYMGTDKGHQWHMQYSPDLVYMMWHKNNHEPNFRKGKYFYDEMNAWLDCSDMTMPRGYVAIVQVSYAKKGIETPYVQGDFGSSRSFKIQKSNAYFKQPQSISNANIQYTSAIKQCHRQIWDYFWPNCCLGEHDVCQWNESLGWREPYIFRATAVSFNMQFAILISGKGPNLDPWDKGFLLPRSYCKFEYFCHKSITCKKYAYVPLMYELNFIKNNTRMVRCSNKDKKLHLRGFKDPENMPTLWALENQPSYELCYDFMYKWFTRMQNEPNNQIRLLQGQTVWKIIHQFLRRFKHFAHINMCFMRREIEYQTPWCLISCTANRAEHCMLLEFSTFSAAFPGFCWICEYEGLMRRGFVSPYTHKGLYGPVQAATGNEIYSKNDHCVFWWDTPEHYQHINVDQESNAGWKSCTAVGHYNWYEKWCWSTDGQYILRCWRNQCIEVSSQCKCWKRCCIQLRNLWGTHPYDRPRAGGPGEQIWGCYICRQWEMAAFKWQEDMTWSWWGMYFPKWCQLDLKNWLWTCMFEANINFIRKRHIYAMVDSDYKHRYRNTHQMSLSDYFCYVHEVNCVNTYFKK\").global_alignment(Peptide(\"YCLHMVKIIWCKDLYTRFKHSHMGYHATYLLTAICIFVFKCWGDTPFGCCNMYFKTSCDWDNFRCKWHWCRKVQIARILSTSYWHLVPGDQVGCCIRKWRIDKVHGHWLMMFFYGYTHCHQIRLQSDLWEWHDSCIMWWSNDNNNWGVVTHVWSQPIYNTIDICWWNRRILLKAVPVQWDYMCIVIDIFPVSCWLLPKRYDPAYLIFKMMETHDVCSFLGYEHPDVIMWTDKGHQWHMQVWQANLEHYSPDLVYMMYINFSKENNHETAPRNCGPWHARMGKYFYDEMNAWLDCSAGIETPYVQGDCIQSSNAYFKQPQYTSAIKQCHRQIWDYFWPNCCPGEHDECQWNESLFGREPYIFRATAVSDNMQFAILISGKGPNSDPWDKRCDYRWCEPFLLHRSYGHFACIFEYFNYAYVYEINMIKNNTRMVKDPENMPNLMANQPSYEMQNEPHPYTCGCTVWKITHCFLRRLKHFAHINEYSCTAEFSNFSAAFPGFCWICEYEGPIWKGLYGPVQAATGNEIYSKNDHCVFWWDHINVDQESNAGWQFTTDSCTAVGHMNWYEINYQTDGQGILRVWRNQCLEVELECIQETNLWGTHPYDRPRVSNNSHGGPGNQIWGCYIKRQWEMAAFKWQEDMTWYWWGMYFPKWCQLDLKNWYKHTLGLVTCMHDFWMRINFIRKPHIRAMVDSDQMSLSDYKCYVHEGTCVCTYWKF\"), read_cost_table(\"BLOSUM62\"))\r\n",
        "print(scores)\r\n",
        "print(path.backtrack)\r\n",
        "print(path)\r\n",
        "print(scores[-1][-1])"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0.000e+00 -5.000e+00 -1.000e+01 ... -3.570e+03 -3.575e+03 -3.580e+03]\n",
            " [-5.000e+00 -2.000e+00 -7.000e+00 ... -3.560e+03 -3.565e+03 -3.570e+03]\n",
            " [-1.000e+01 -7.000e+00 -2.000e+00 ... -3.551e+03 -3.556e+03 -3.561e+03]\n",
            " ...\n",
            " [-3.980e+03 -3.968e+03 -3.954e+03 ...  1.747e+03  1.742e+03  1.742e+03]\n",
            " [-3.985e+03 -3.973e+03 -3.959e+03 ...  1.742e+03  1.752e+03  1.747e+03]\n",
            " [-3.990e+03 -3.978e+03 -3.964e+03 ...  1.737e+03  1.747e+03  1.749e+03]]\n",
            "[[1. 2. 2. ... 2. 2. 2.]\n",
            " [1. 0. 2. ... 2. 2. 2.]\n",
            " [1. 1. 0. ... 2. 2. 2.]\n",
            " ...\n",
            " [1. 1. 1. ... 0. 2. 0.]\n",
            " [1. 1. 1. ... 1. 0. 2.]\n",
            " [1. 1. 1. ... 1. 1. 0.]]\n",
            "798 716 0.0\n",
            "797 715 0.0\n",
            "796 714 0.0\n",
            "795 713 0.0\n",
            "794 712 0.0\n",
            "793 711 0.0\n",
            "792 710 0.0\n",
            "791 709 0.0\n",
            "790 708 0.0\n",
            "789 707 0.0\n",
            "788 706 0.0\n",
            "787 705 0.0\n",
            "786 704 0.0\n",
            "785 703 0.0\n",
            "784 702 0.0\n",
            "783 701 0.0\n",
            "782 700 0.0\n",
            "781 699 0.0\n",
            "780 698 0.0\n",
            "779 697 0.0\n",
            "778 696 0.0\n",
            "777 695 0.0\n",
            "776 694 0.0\n",
            "775 693 1.0\n",
            "774 693 1.0\n",
            "773 693 1.0\n",
            "772 693 1.0\n",
            "771 693 1.0\n",
            "770 693 1.0\n",
            "769 693 1.0\n",
            "768 693 1.0\n",
            "767 693 1.0\n",
            "766 693 0.0\n",
            "765 692 0.0\n",
            "764 691 0.0\n",
            "763 690 0.0\n",
            "762 689 0.0\n",
            "761 688 0.0\n",
            "760 687 0.0\n",
            "759 686 0.0\n",
            "758 685 0.0\n",
            "757 684 0.0\n",
            "756 683 0.0\n",
            "755 682 0.0\n",
            "754 681 0.0\n",
            "753 680 0.0\n",
            "752 679 0.0\n",
            "751 678 0.0\n",
            "750 677 0.0\n",
            "749 676 0.0\n",
            "748 675 0.0\n",
            "747 674 0.0\n",
            "746 673 2.0\n",
            "746 672 2.0\n",
            "746 671 0.0\n",
            "745 670 0.0\n",
            "744 669 0.0\n",
            "743 668 2.0\n",
            "743 667 2.0\n",
            "743 666 0.0\n",
            "742 665 0.0\n",
            "741 664 2.0\n",
            "741 663 2.0\n",
            "741 662 2.0\n",
            "741 661 2.0\n",
            "741 660 0.0\n",
            "740 659 0.0\n",
            "739 658 0.0\n",
            "738 657 0.0\n",
            "737 656 0.0\n",
            "736 655 0.0\n",
            "735 654 0.0\n",
            "734 653 0.0\n",
            "733 652 0.0\n",
            "732 651 0.0\n",
            "731 650 0.0\n",
            "730 649 0.0\n",
            "729 648 0.0\n",
            "728 647 0.0\n",
            "727 646 0.0\n",
            "726 645 0.0\n",
            "725 644 0.0\n",
            "724 643 0.0\n",
            "723 642 0.0\n",
            "722 641 0.0\n",
            "721 640 0.0\n",
            "720 639 0.0\n",
            "719 638 0.0\n",
            "718 637 0.0\n",
            "717 636 0.0\n",
            "716 635 0.0\n",
            "715 634 0.0\n",
            "714 633 0.0\n",
            "713 632 0.0\n",
            "712 631 0.0\n",
            "711 630 0.0\n",
            "710 629 0.0\n",
            "709 628 0.0\n",
            "708 627 0.0\n",
            "707 626 0.0\n",
            "706 625 0.0\n",
            "705 624 0.0\n",
            "704 623 0.0\n",
            "703 622 0.0\n",
            "702 621 0.0\n",
            "701 620 0.0\n",
            "700 619 0.0\n",
            "699 618 0.0\n",
            "698 617 0.0\n",
            "697 616 0.0\n",
            "696 615 0.0\n",
            "695 614 0.0\n",
            "694 613 2.0\n",
            "694 612 2.0\n",
            "694 611 2.0\n",
            "694 610 2.0\n",
            "694 609 0.0\n",
            "693 608 2.0\n",
            "693 607 0.0\n",
            "692 606 0.0\n",
            "691 605 0.0\n",
            "690 604 0.0\n",
            "689 603 0.0\n",
            "688 602 0.0\n",
            "687 601 0.0\n",
            "686 600 0.0\n",
            "685 599 0.0\n",
            "684 598 0.0\n",
            "683 597 0.0\n",
            "682 596 0.0\n",
            "681 595 0.0\n",
            "680 594 0.0\n",
            "679 593 0.0\n",
            "678 592 0.0\n",
            "677 591 1.0\n",
            "676 591 1.0\n",
            "675 591 1.0\n",
            "674 591 1.0\n",
            "673 591 1.0\n",
            "672 591 0.0\n",
            "671 590 0.0\n",
            "670 589 0.0\n",
            "669 588 0.0\n",
            "668 587 1.0\n",
            "667 587 1.0\n",
            "666 587 0.0\n",
            "665 586 0.0\n",
            "664 585 0.0\n",
            "663 584 0.0\n",
            "662 583 0.0\n",
            "661 582 0.0\n",
            "660 581 0.0\n",
            "659 580 0.0\n",
            "658 579 0.0\n",
            "657 578 0.0\n",
            "656 577 0.0\n",
            "655 576 0.0\n",
            "654 575 0.0\n",
            "653 574 0.0\n",
            "652 573 0.0\n",
            "651 572 0.0\n",
            "650 571 0.0\n",
            "649 570 0.0\n",
            "648 569 0.0\n",
            "647 568 0.0\n",
            "646 567 1.0\n",
            "645 567 0.0\n",
            "644 566 0.0\n",
            "643 565 0.0\n",
            "642 564 0.0\n",
            "641 563 0.0\n",
            "640 562 0.0\n",
            "639 561 0.0\n",
            "638 560 0.0\n",
            "637 559 0.0\n",
            "636 558 0.0\n",
            "635 557 0.0\n",
            "634 556 0.0\n",
            "633 555 0.0\n",
            "632 554 2.0\n",
            "632 553 2.0\n",
            "632 552 2.0\n",
            "632 551 2.0\n",
            "632 550 0.0\n",
            "631 549 0.0\n",
            "630 548 0.0\n",
            "629 547 0.0\n",
            "628 546 0.0\n",
            "627 545 0.0\n",
            "626 544 0.0\n",
            "625 543 0.0\n",
            "624 542 0.0\n",
            "623 541 0.0\n",
            "622 540 0.0\n",
            "621 539 0.0\n",
            "620 538 1.0\n",
            "619 538 1.0\n",
            "618 538 1.0\n",
            "617 538 0.0\n",
            "616 537 1.0\n",
            "615 537 1.0\n",
            "614 537 1.0\n",
            "613 537 0.0\n",
            "612 536 0.0\n",
            "611 535 0.0\n",
            "610 534 0.0\n",
            "609 533 0.0\n",
            "608 532 0.0\n",
            "607 531 0.0\n",
            "606 530 0.0\n",
            "605 529 0.0\n",
            "604 528 0.0\n",
            "603 527 0.0\n",
            "602 526 0.0\n",
            "601 525 0.0\n",
            "600 524 0.0\n",
            "599 523 0.0\n",
            "598 522 0.0\n",
            "597 521 0.0\n",
            "596 520 0.0\n",
            "595 519 0.0\n",
            "594 518 0.0\n",
            "593 517 0.0\n",
            "592 516 0.0\n",
            "591 515 0.0\n",
            "590 514 0.0\n",
            "589 513 0.0\n",
            "588 512 0.0\n",
            "587 511 0.0\n",
            "586 510 1.0\n",
            "585 510 0.0\n",
            "584 509 0.0\n",
            "583 508 0.0\n",
            "582 507 1.0\n",
            "581 507 1.0\n",
            "580 507 1.0\n",
            "579 507 1.0\n",
            "578 507 1.0\n",
            "577 507 1.0\n",
            "576 507 1.0\n",
            "575 507 1.0\n",
            "574 507 0.0\n",
            "573 506 0.0\n",
            "572 505 0.0\n",
            "571 504 0.0\n",
            "570 503 0.0\n",
            "569 502 0.0\n",
            "568 501 0.0\n",
            "567 500 0.0\n",
            "566 499 0.0\n",
            "565 498 0.0\n",
            "564 497 0.0\n",
            "563 496 0.0\n",
            "562 495 0.0\n",
            "561 494 0.0\n",
            "560 493 0.0\n",
            "559 492 0.0\n",
            "558 491 0.0\n",
            "557 490 0.0\n",
            "556 489 0.0\n",
            "555 488 1.0\n",
            "554 488 1.0\n",
            "553 488 1.0\n",
            "552 488 1.0\n",
            "551 488 1.0\n",
            "550 488 1.0\n",
            "549 488 0.0\n",
            "548 487 1.0\n",
            "547 487 1.0\n",
            "546 487 1.0\n",
            "545 487 0.0\n",
            "544 486 0.0\n",
            "543 485 0.0\n",
            "542 484 0.0\n",
            "541 483 1.0\n",
            "540 483 1.0\n",
            "539 483 1.0\n",
            "538 483 1.0\n",
            "537 483 1.0\n",
            "536 483 1.0\n",
            "535 483 1.0\n",
            "534 483 0.0\n",
            "533 482 1.0\n",
            "532 482 1.0\n",
            "531 482 0.0\n",
            "530 481 1.0\n",
            "529 481 1.0\n",
            "528 481 1.0\n",
            "527 481 1.0\n",
            "526 481 1.0\n",
            "525 481 1.0\n",
            "524 481 0.0\n",
            "523 480 0.0\n",
            "522 479 0.0\n",
            "521 478 0.0\n",
            "520 477 0.0\n",
            "519 476 0.0\n",
            "518 475 0.0\n",
            "517 474 0.0\n",
            "516 473 0.0\n",
            "515 472 0.0\n",
            "514 471 0.0\n",
            "513 470 0.0\n",
            "512 469 0.0\n",
            "511 468 0.0\n",
            "510 467 0.0\n",
            "509 466 0.0\n",
            "508 465 0.0\n",
            "507 464 0.0\n",
            "506 463 0.0\n",
            "505 462 0.0\n",
            "504 461 0.0\n",
            "503 460 0.0\n",
            "502 459 1.0\n",
            "501 459 1.0\n",
            "500 459 0.0\n",
            "499 458 0.0\n",
            "498 457 0.0\n",
            "497 456 0.0\n",
            "496 455 1.0\n",
            "495 455 0.0\n",
            "494 454 0.0\n",
            "493 453 0.0\n",
            "492 452 0.0\n",
            "491 451 0.0\n",
            "490 450 1.0\n",
            "489 450 1.0\n",
            "488 450 1.0\n",
            "487 450 1.0\n",
            "486 450 1.0\n",
            "485 450 1.0\n",
            "484 450 1.0\n",
            "483 450 0.0\n",
            "482 449 1.0\n",
            "481 449 1.0\n",
            "480 449 1.0\n",
            "479 449 1.0\n",
            "478 449 1.0\n",
            "477 449 0.0\n",
            "476 448 0.0\n",
            "475 447 0.0\n",
            "474 446 0.0\n",
            "473 445 0.0\n",
            "472 444 0.0\n",
            "471 443 1.0\n",
            "470 443 1.0\n",
            "469 443 0.0\n",
            "468 442 0.0\n",
            "467 441 0.0\n",
            "466 440 0.0\n",
            "465 439 0.0\n",
            "464 438 0.0\n",
            "463 437 0.0\n",
            "462 436 0.0\n",
            "461 435 0.0\n",
            "460 434 0.0\n",
            "459 433 0.0\n",
            "458 432 0.0\n",
            "457 431 0.0\n",
            "456 430 0.0\n",
            "455 429 0.0\n",
            "454 428 0.0\n",
            "453 427 1.0\n",
            "452 427 0.0\n",
            "451 426 0.0\n",
            "450 425 0.0\n",
            "449 424 0.0\n",
            "448 423 0.0\n",
            "447 422 1.0\n",
            "446 422 0.0\n",
            "445 421 0.0\n",
            "444 420 0.0\n",
            "443 419 0.0\n",
            "442 418 0.0\n",
            "441 417 0.0\n",
            "440 416 0.0\n",
            "439 415 0.0\n",
            "438 414 1.0\n",
            "437 414 1.0\n",
            "436 414 0.0\n",
            "435 413 1.0\n",
            "434 413 0.0\n",
            "433 412 0.0\n",
            "432 411 0.0\n",
            "431 410 0.0\n",
            "430 409 0.0\n",
            "429 408 0.0\n",
            "428 407 0.0\n",
            "427 406 0.0\n",
            "426 405 0.0\n",
            "425 404 0.0\n",
            "424 403 0.0\n",
            "423 402 0.0\n",
            "422 401 0.0\n",
            "421 400 0.0\n",
            "420 399 0.0\n",
            "419 398 0.0\n",
            "418 397 0.0\n",
            "417 396 0.0\n",
            "416 395 0.0\n",
            "415 394 1.0\n",
            "414 394 0.0\n",
            "413 393 0.0\n",
            "412 392 0.0\n",
            "411 391 0.0\n",
            "410 390 0.0\n",
            "409 389 1.0\n",
            "408 389 1.0\n",
            "407 389 0.0\n",
            "406 388 1.0\n",
            "405 388 1.0\n",
            "404 388 1.0\n",
            "403 388 1.0\n",
            "402 388 1.0\n",
            "401 388 0.0\n",
            "400 387 0.0\n",
            "399 386 0.0\n",
            "398 385 0.0\n",
            "397 384 0.0\n",
            "396 383 0.0\n",
            "395 382 0.0\n",
            "394 381 0.0\n",
            "393 380 0.0\n",
            "392 379 0.0\n",
            "391 378 0.0\n",
            "390 377 0.0\n",
            "389 376 0.0\n",
            "388 375 0.0\n",
            "387 374 0.0\n",
            "386 373 0.0\n",
            "385 372 0.0\n",
            "384 371 0.0\n",
            "383 370 0.0\n",
            "382 369 0.0\n",
            "381 368 0.0\n",
            "380 367 0.0\n",
            "379 366 0.0\n",
            "378 365 0.0\n",
            "377 364 0.0\n",
            "376 363 0.0\n",
            "375 362 0.0\n",
            "374 361 0.0\n",
            "373 360 0.0\n",
            "372 359 0.0\n",
            "371 358 0.0\n",
            "370 357 0.0\n",
            "369 356 0.0\n",
            "368 355 1.0\n",
            "367 355 0.0\n",
            "366 354 2.0\n",
            "366 353 0.0\n",
            "365 352 0.0\n",
            "364 351 0.0\n",
            "363 350 0.0\n",
            "362 349 0.0\n",
            "361 348 0.0\n",
            "360 347 0.0\n",
            "359 346 0.0\n",
            "358 345 0.0\n",
            "357 344 0.0\n",
            "356 343 0.0\n",
            "355 342 0.0\n",
            "354 341 0.0\n",
            "353 340 0.0\n",
            "352 339 0.0\n",
            "351 338 0.0\n",
            "350 337 0.0\n",
            "349 336 0.0\n",
            "348 335 0.0\n",
            "347 334 0.0\n",
            "346 333 0.0\n",
            "345 332 0.0\n",
            "344 331 0.0\n",
            "343 330 0.0\n",
            "342 329 0.0\n",
            "341 328 0.0\n",
            "340 327 0.0\n",
            "339 326 0.0\n",
            "338 325 0.0\n",
            "337 324 0.0\n",
            "336 323 0.0\n",
            "335 322 0.0\n",
            "334 321 0.0\n",
            "333 320 0.0\n",
            "332 319 1.0\n",
            "331 319 1.0\n",
            "330 319 1.0\n",
            "329 319 1.0\n",
            "328 319 1.0\n",
            "327 319 1.0\n",
            "326 319 1.0\n",
            "325 319 1.0\n",
            "324 319 0.0\n",
            "323 318 0.0\n",
            "322 317 0.0\n",
            "321 316 0.0\n",
            "320 315 0.0\n",
            "319 314 0.0\n",
            "318 313 0.0\n",
            "317 312 0.0\n",
            "316 311 0.0\n",
            "315 310 0.0\n",
            "314 309 0.0\n",
            "313 308 0.0\n",
            "312 307 1.0\n",
            "311 307 1.0\n",
            "310 307 1.0\n",
            "309 307 1.0\n",
            "308 307 1.0\n",
            "307 307 0.0\n",
            "306 306 1.0\n",
            "305 306 1.0\n",
            "304 306 0.0\n",
            "303 305 0.0\n",
            "302 304 0.0\n",
            "301 303 0.0\n",
            "300 302 0.0\n",
            "299 301 0.0\n",
            "298 300 0.0\n",
            "297 299 0.0\n",
            "296 298 0.0\n",
            "295 297 0.0\n",
            "294 296 1.0\n",
            "293 296 1.0\n",
            "292 296 1.0\n",
            "291 296 1.0\n",
            "290 296 1.0\n",
            "289 296 1.0\n",
            "288 296 1.0\n",
            "287 296 1.0\n",
            "286 296 1.0\n",
            "285 296 0.0\n",
            "284 295 1.0\n",
            "283 295 1.0\n",
            "282 295 1.0\n",
            "281 295 1.0\n",
            "280 295 1.0\n",
            "279 295 1.0\n",
            "278 295 1.0\n",
            "277 295 1.0\n",
            "276 295 1.0\n",
            "275 295 0.0\n",
            "274 294 0.0\n",
            "273 293 0.0\n",
            "272 292 0.0\n",
            "271 291 0.0\n",
            "270 290 0.0\n",
            "269 289 0.0\n",
            "268 288 0.0\n",
            "267 287 0.0\n",
            "266 286 0.0\n",
            "265 285 0.0\n",
            "264 284 0.0\n",
            "263 283 0.0\n",
            "262 282 0.0\n",
            "261 281 0.0\n",
            "260 280 0.0\n",
            "259 279 0.0\n",
            "258 278 2.0\n",
            "258 277 2.0\n",
            "258 276 0.0\n",
            "257 275 2.0\n",
            "257 274 2.0\n",
            "257 273 2.0\n",
            "257 272 0.0\n",
            "256 271 2.0\n",
            "256 270 0.0\n",
            "255 269 2.0\n",
            "255 268 2.0\n",
            "255 267 0.0\n",
            "254 266 0.0\n",
            "253 265 0.0\n",
            "252 264 0.0\n",
            "251 263 2.0\n",
            "251 262 0.0\n",
            "250 261 2.0\n",
            "250 260 2.0\n",
            "250 259 0.0\n",
            "249 258 2.0\n",
            "249 257 0.0\n",
            "248 256 0.0\n",
            "247 255 0.0\n",
            "246 254 0.0\n",
            "245 253 0.0\n",
            "244 252 0.0\n",
            "243 251 0.0\n",
            "242 250 0.0\n",
            "241 249 0.0\n",
            "240 248 0.0\n",
            "239 247 2.0\n",
            "239 246 2.0\n",
            "239 245 2.0\n",
            "239 244 2.0\n",
            "239 243 2.0\n",
            "239 242 2.0\n",
            "239 241 2.0\n",
            "239 240 2.0\n",
            "239 239 0.0\n",
            "238 238 0.0\n",
            "237 237 0.0\n",
            "236 236 0.0\n",
            "235 235 0.0\n",
            "234 234 0.0\n",
            "233 233 0.0\n",
            "232 232 0.0\n",
            "231 231 0.0\n",
            "230 230 0.0\n",
            "229 229 0.0\n",
            "228 228 0.0\n",
            "227 227 1.0\n",
            "226 227 1.0\n",
            "225 227 1.0\n",
            "224 227 1.0\n",
            "223 227 1.0\n",
            "222 227 0.0\n",
            "221 226 0.0\n",
            "220 225 0.0\n",
            "219 224 1.0\n",
            "218 224 0.0\n",
            "217 223 0.0\n",
            "216 222 1.0\n",
            "215 222 0.0\n",
            "214 221 0.0\n",
            "213 220 0.0\n",
            "212 219 0.0\n",
            "211 218 0.0\n",
            "210 217 0.0\n",
            "209 216 0.0\n",
            "208 215 1.0\n",
            "207 215 0.0\n",
            "206 214 0.0\n",
            "205 213 1.0\n",
            "204 213 1.0\n",
            "203 213 1.0\n",
            "202 213 0.0\n",
            "201 212 1.0\n",
            "200 212 1.0\n",
            "199 212 0.0\n",
            "198 211 0.0\n",
            "197 210 0.0\n",
            "196 209 0.0\n",
            "195 208 0.0\n",
            "194 207 1.0\n",
            "193 207 1.0\n",
            "192 207 1.0\n",
            "191 207 0.0\n",
            "190 206 0.0\n",
            "189 205 0.0\n",
            "188 204 0.0\n",
            "187 203 0.0\n",
            "186 202 0.0\n",
            "185 201 0.0\n",
            "184 200 0.0\n",
            "183 199 0.0\n",
            "182 198 0.0\n",
            "181 197 0.0\n",
            "180 196 0.0\n",
            "179 195 0.0\n",
            "178 194 0.0\n",
            "177 193 1.0\n",
            "176 193 0.0\n",
            "175 192 0.0\n",
            "174 191 2.0\n",
            "174 190 0.0\n",
            "173 189 0.0\n",
            "172 188 2.0\n",
            "172 187 2.0\n",
            "172 186 2.0\n",
            "172 185 0.0\n",
            "171 184 0.0\n",
            "170 183 0.0\n",
            "169 182 0.0\n",
            "168 181 0.0\n",
            "167 180 0.0\n",
            "166 179 0.0\n",
            "165 178 0.0\n",
            "164 177 0.0\n",
            "163 176 0.0\n",
            "162 175 0.0\n",
            "161 174 0.0\n",
            "160 173 0.0\n",
            "159 172 0.0\n",
            "158 171 0.0\n",
            "157 170 0.0\n",
            "156 169 2.0\n",
            "156 168 0.0\n",
            "155 167 0.0\n",
            "154 166 2.0\n",
            "154 165 2.0\n",
            "154 164 2.0\n",
            "154 163 2.0\n",
            "154 162 0.0\n",
            "153 161 0.0\n",
            "152 160 2.0\n",
            "152 159 0.0\n",
            "151 158 0.0\n",
            "150 157 0.0\n",
            "149 156 2.0\n",
            "149 155 2.0\n",
            "149 154 2.0\n",
            "149 153 2.0\n",
            "149 152 2.0\n",
            "149 151 2.0\n",
            "149 150 2.0\n",
            "149 149 0.0\n",
            "148 148 0.0\n",
            "147 147 0.0\n",
            "146 146 0.0\n",
            "145 145 0.0\n",
            "144 144 0.0\n",
            "143 143 0.0\n",
            "142 142 0.0\n",
            "141 141 0.0\n",
            "140 140 0.0\n",
            "139 139 0.0\n",
            "138 138 0.0\n",
            "137 137 0.0\n",
            "136 136 0.0\n",
            "135 135 0.0\n",
            "134 134 0.0\n",
            "133 133 0.0\n",
            "132 132 0.0\n",
            "131 131 2.0\n",
            "131 130 0.0\n",
            "130 129 2.0\n",
            "130 128 2.0\n",
            "130 127 0.0\n",
            "129 126 0.0\n",
            "128 125 1.0\n",
            "127 125 0.0\n",
            "126 124 0.0\n",
            "125 123 0.0\n",
            "124 122 0.0\n",
            "123 121 2.0\n",
            "123 120 2.0\n",
            "123 119 2.0\n",
            "123 118 2.0\n",
            "123 117 2.0\n",
            "123 116 2.0\n",
            "123 115 2.0\n",
            "123 114 0.0\n",
            "122 113 0.0\n",
            "121 112 0.0\n",
            "120 111 0.0\n",
            "119 110 0.0\n",
            "118 109 0.0\n",
            "117 108 0.0\n",
            "116 107 0.0\n",
            "115 106 0.0\n",
            "114 105 0.0\n",
            "113 104 0.0\n",
            "112 103 0.0\n",
            "111 102 0.0\n",
            "110 101 0.0\n",
            "109 100 0.0\n",
            "108 99 0.0\n",
            "107 98 0.0\n",
            "106 97 0.0\n",
            "105 96 0.0\n",
            "104 95 0.0\n",
            "103 94 0.0\n",
            "102 93 0.0\n",
            "101 92 0.0\n",
            "100 91 1.0\n",
            "99 91 0.0\n",
            "98 90 0.0\n",
            "97 89 1.0\n",
            "96 89 0.0\n",
            "95 88 0.0\n",
            "94 87 0.0\n",
            "93 86 0.0\n",
            "92 85 0.0\n",
            "91 84 0.0\n",
            "90 83 0.0\n",
            "89 82 0.0\n",
            "88 81 1.0\n",
            "87 81 0.0\n",
            "86 80 1.0\n",
            "85 80 0.0\n",
            "84 79 0.0\n",
            "83 78 0.0\n",
            "82 77 0.0\n",
            "81 76 0.0\n",
            "80 75 0.0\n",
            "79 74 0.0\n",
            "78 73 0.0\n",
            "77 72 0.0\n",
            "76 71 1.0\n",
            "75 71 1.0\n",
            "74 71 1.0\n",
            "73 71 1.0\n",
            "72 71 0.0\n",
            "71 70 1.0\n",
            "70 70 1.0\n",
            "69 70 0.0\n",
            "68 69 0.0\n",
            "67 68 0.0\n",
            "66 67 0.0\n",
            "65 66 0.0\n",
            "64 65 0.0\n",
            "63 64 0.0\n",
            "62 63 0.0\n",
            "61 62 0.0\n",
            "60 61 0.0\n",
            "59 60 0.0\n",
            "58 59 1.0\n",
            "57 59 0.0\n",
            "56 58 0.0\n",
            "55 57 2.0\n",
            "55 56 0.0\n",
            "54 55 0.0\n",
            "53 54 0.0\n",
            "52 53 0.0\n",
            "51 52 0.0\n",
            "50 51 0.0\n",
            "49 50 0.0\n",
            "48 49 0.0\n",
            "47 48 0.0\n",
            "46 47 0.0\n",
            "45 46 0.0\n",
            "44 45 0.0\n",
            "43 44 0.0\n",
            "42 43 0.0\n",
            "41 42 0.0\n",
            "40 41 0.0\n",
            "39 40 0.0\n",
            "38 39 2.0\n",
            "38 38 0.0\n",
            "37 37 2.0\n",
            "37 36 2.0\n",
            "37 35 2.0\n",
            "37 34 2.0\n",
            "37 33 2.0\n",
            "37 32 0.0\n",
            "36 31 2.0\n",
            "36 30 2.0\n",
            "36 29 0.0\n",
            "35 28 0.0\n",
            "34 27 0.0\n",
            "33 26 0.0\n",
            "32 25 0.0\n",
            "31 24 0.0\n",
            "30 23 0.0\n",
            "29 22 0.0\n",
            "28 21 0.0\n",
            "27 20 0.0\n",
            "26 19 0.0\n",
            "25 18 0.0\n",
            "24 17 0.0\n",
            "23 16 0.0\n",
            "22 15 0.0\n",
            "21 14 0.0\n",
            "20 13 0.0\n",
            "19 12 0.0\n",
            "18 11 0.0\n",
            "17 10 0.0\n",
            "16 9 0.0\n",
            "15 8 1.0\n",
            "14 8 0.0\n",
            "13 7 1.0\n",
            "12 7 0.0\n",
            "11 6 0.0\n",
            "10 5 0.0\n",
            "9 4 0.0\n",
            "8 3 1.0\n",
            "7 3 0.0\n",
            "6 2 0.0\n",
            "5 1 1.0\n",
            "4 1 1.0\n",
            "3 1 0.0\n",
            "2 0 1.0\n",
            "1 0 1.0\n",
            "RAYRFVVANGFRNATIWCKPFYTRFKHSHMGYHATY--N-----V-KCWGDTPFGMAHSILGC-CNMYYSFRCKWHWCIDTMAPSKVQLARILSHTTSYWHLCSGNDRWYDCCIRKWEIDQVHGHTLMMFFY-------MRLQCSD--R-HDLCIMWWSNDNNNWGVV-------IYN-IK----HR-ILLKAVPRQWDYMCVV---YR-SCHWLLPKRYDPAYLIFCWDNVQQCFEHPATEQECDICADDVYSRDVICKDPYMGTDKGHQWHMQ--------YSPDLVYMMW-H--K-NNHE--P-N---F--RKGKYFYDEMNAWLDCSDMTMPRGYVAIVQVSYAKKGIETPYVQGDFGSSRSFKIQKSNAYFKQPQSISNANIQYTSAIKQCHRQIWDYFWPNCCLGEHDVCQWNESL-GWREPYIFRATAVSFNMQFAILISGKGPNLDPWDKGFLLPRSYCKFEYFCHKSITCKKYAYVPLMYELNFIKNNTRMVRCSNKDKKLHLRGFKDPENMPTLWALENQPSYELCYDFMYKWFTRMQNEPNNQIRLLQGQTVWKIIHQFLRRFKHFAHINMCFMRREIEYQTPWCLISCTANRAEHCMLLEFSTFSAAFPGFCWICEYEGLMRRGFVSPYTHKGLYGPVQAATGNEIYSKNDHCVFWWDTPEHYQHINVDQESNAGWK----SCTAVGHYNWYEKWCWSTDGQYILRCWRNQCIEVSSQCKCWKRCCIQLRNLWGTHPYDRPR-A----GGPGEQIWGCYICRQWEMAAFKWQEDMTWSWWGMYFPKWCQLDLKNW----LW--TCM--FEANINFIRKRHIYAMVDSDYKHRYRNTHQMSLSDYFCYVHEVNCVNTYFKK\n",
            "--Y--CL-HMVK-I-IWCKDLYTRFKHSHMGYHATYLLTAICIFVFKCWGDTPFGCCNMYFKTSCD-WDNFRCKWHWC--R----KVQIARILS-T-SYWHLVPG-DQ-VGCCIRKWRIDKVHGHWLMMFFYGYTHCHQIRLQ-SDLWEWHDSCIMWWSNDNNNWGVVTHVWSQPIYNTIDICWWNRRILLKAVPVQWDYMCIVIDIFPVSC-WLLPKRYDPAYLIF---KMMET--H---DV-CSFLGYE-HP-DVI-----MWTDKGHQWHMQVWQANLEHYSPDLVYMMYINFSKENNHETAPRNCGPWHARMGKYFYDEMNAWLDCS---------A---------GIETPYVQGD--C-----IQSSNAYFKQPQ--------YTSAIKQCHRQIWDYFWPNCCPGEHDECQWNESLFG-REPYIFRATAVSDNMQFAILISGKGPNSDPWDK-----R--CDYRW-CEPFLLHRSYGHFACIFEY-F--NYAYVYEI-NMIKN-NTRMVKDPENMPNLMA--NQPSYE-----M-------QNEPH-PYTC--GCTVWKITHCFLRRLKHFAHIN------E--Y-------SCTA---E------FSNFSAAFPGFCWICEYEG--------PIW-KGLYGPVQAATGNEIYSKNDHCVFWWD---H---INVDQESNAGWQFTTDSCTAVGHMNWYEI-NYQTDGQGILRVWRNQCLEV--ELEC-----IQETNLWGTHPYDRPRVSNNSHGGPGNQIWGCYIKRQWEMAAFKWQEDMTWYWWGMYFPKWCQLDLKNWYKHTLGLVTCMHDFWMRINFIRKPHIRAMVDSD---------QMSLSDYKCYVHEGTCVCTYWKF\n",
            "1749.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qe5FTNNTreAt"
      },
      "source": [
        ""
      ],
      "execution_count": 58,
      "outputs": []
    }
  ]
}